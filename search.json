[
  {
    "objectID": "slides/fr/index.html#qui-sommes-nous",
    "href": "slides/fr/index.html#qui-sommes-nous",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Qui sommes-nous ?",
    "text": "Qui sommes-nous ?\n\nData scientists √† l‚ÄôInsee\n\n√âquipes d‚Äôinnovation m√©thodologique et informatique\nAccompagnement des projets de datascience\n\nContactez-nous\n\nromain.avouac at insee dot fr\nthomas.faria at insee dot fr\ntom.seimandi at insee dot fr"
  },
  {
    "objectID": "slides/fr/index.html#contexte",
    "href": "slides/fr/index.html#contexte",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Contexte",
    "text": "Contexte\n\nDifficult√© de passer des exp√©rimentations √† la mise en production de mod√®le de machine learning\nTirer parti des meilleures pratiques en g√©nie logiciel\n\nAm√©liorer la reproductibilit√© des analyses\nD√©ployer des applications de mani√®re robuste\nSurveiller les applications en cours d‚Äôex√©cution"
  },
  {
    "objectID": "slides/fr/index.html#lapproche-devops",
    "href": "slides/fr/index.html#lapproche-devops",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "L‚Äôapproche DevOps",
    "text": "L‚Äôapproche DevOps\n\nUnifier le d√©veloppement (dev) et l‚Äôadministration syst√®me (ops)\n\nR√©duire le temps de d√©veloppement\nMaintenir la qualit√© logicielle"
  },
  {
    "objectID": "slides/fr/index.html#lapproche-mlops",
    "href": "slides/fr/index.html#lapproche-mlops",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "L‚Äôapproche MLOps",
    "text": "L‚Äôapproche MLOps\n\nInt√©grer les sp√©cificit√©s des projets de machine learning\n\nExp√©rimentation\nAm√©lioration continue"
  },
  {
    "objectID": "slides/fr/index.html#mlops-principes",
    "href": "slides/fr/index.html#mlops-principes",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "MLOps : principes",
    "text": "MLOps : principes\n\nReproductibilit√©\nContr√¥le de version\nAutomatisation\nSurveillance\nCollaboration"
  },
  {
    "objectID": "slides/fr/index.html#pourquoi-mlflow",
    "href": "slides/fr/index.html#pourquoi-mlflow",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Pourquoi MLflow ?",
    "text": "Pourquoi MLflow ?\n\nDe nombreux frameworks impl√©mentent les principes du MLOps\nAvantages de MLflow :\n\nOpen-source\nCouvre l‚Äôenti√®ret√© du cycle de vie d‚Äôun mod√®le ML\nAgnostique au package ML utilis√©\nExp√©rience accumul√©e"
  },
  {
    "objectID": "slides/fr/index.html#plateforme-de-formation-le-ssp-cloud",
    "href": "slides/fr/index.html#plateforme-de-formation-le-ssp-cloud",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Plateforme de formation : le SSP Cloud",
    "text": "Plateforme de formation : le SSP Cloud\n\nUn environnement d‚Äôinnovation ouvert\n\nCluster Kubernetes\nStockage d‚Äôobjets compatible S3\nRessources de calcul (y compris des GPU)\n\nBas√© sur le projet Onyxia\n\nUne interface conviviale pour les utilisateurs permettant de lancer des services de datascience\nUn catalogue de services couvrant l‚Äôensemble du cycle de vie des projets de datascience"
  },
  {
    "objectID": "slides/fr/index.html#plan",
    "href": "slides/fr/index.html#plan",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Plan",
    "text": "Plan\n1Ô∏è‚É£ Introduction √† MLFlow\n\n2Ô∏è‚É£ Un exemple concret: pr√©diction du code APE pour les entreprises\n\n\n3Ô∏è‚É£ Servir un mod√®le de ML √† des utilisateurs\n\n\n4Ô∏è‚É£ Maintenance d‚Äôun mod√®le en production\n\n\n5Ô∏è‚É£ Distribuer l‚Äôoptimisation des hyperparam√®tres"
  },
  {
    "objectID": "slides/fr/index.html#app0",
    "href": "slides/fr/index.html#app0",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 0",
    "text": "Application 0\n\nSans GitAvec Git\n\n\n\n\n\nPr√©paration de l‚Äôenvironnement de travail\n\n\n\nCr√©ez un compte sur le SSP Cloud en utilisant votre adresse e-mail professionnelle.\nLancez un service MLflow en cliquant sur cette URL.\nLancez un service VSCode-python en cliquant sur cette URL.\nOuvrez le service VSCode-python et saisissez le mot de passe du service.\nVous √™tes pr√™t !\n\n\n\n\n\n\n\n\n\nPr√©paration de l‚Äôenvironnement de travail\n\n\n\nSi ce n‚Äôest pas d√©j√† fait, cr√©ez un compte Github. Cr√©ez une copie du d√©p√¥t de la formation dans votre espace personnel en forkant le d√©p√¥t.\nSi ce n‚Äôest pas d√©j√† fait, cr√©ez un compte sur le SSP Cloud en utilisant votre adresse e-mail professionnelle.\nLancez un service MLflow en cliquant sur cette URL.\nLancez un service VSCode-python en cliquant sur cette URL.\nOuvrez le service VSCode-python et saisissez le mot de passe du service.\nDans VSCode, ouvrez un terminal et clonez le d√©p√¥t que vous venez de fork (modifiez les deux premi√®res lignes) :\nGIT_REPO=formation-mlops\nGIT_USERNAME=InseeFrLab\n\ngit clone https://github.com/$GIT_USERNAME/$GIT_REPO.git\ncd $GIT_REPO\nInstallez les packages n√©cessaires pour la formation (avec uv):\nuv sync\nuv run python -m nltk.downloader stopwords\nVous √™tes pr√™t !"
  },
  {
    "objectID": "slides/fr/index.html#tracking-server",
    "href": "slides/fr/index.html#tracking-server",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Tracking server",
    "text": "Tracking server\n\n‚ÄúUne API et une interface utilisateur pour enregistrer les param√®tres, les versions du code, les m√©triques et les artefacts‚Äù"
  },
  {
    "objectID": "slides/fr/index.html#projects",
    "href": "slides/fr/index.html#projects",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Projects",
    "text": "Projects\n\n‚ÄúUn format standard pour ‚Äòpackager‚Äô du code r√©utilisable en datascience‚Äù"
  },
  {
    "objectID": "slides/fr/index.html#models",
    "href": "slides/fr/index.html#models",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Models",
    "text": "Models\n\n‚ÄúUne convention pour ‚Äòpackager‚Äô des mod√®les de machine learning sous plusieurs formes‚Äù"
  },
  {
    "objectID": "slides/fr/index.html#model-registry",
    "href": "slides/fr/index.html#model-registry",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Model registry",
    "text": "Model registry\n\n‚ÄúUn entrep√¥t centralis√© de mod√®les, un ensemble d‚ÄôAPI et une interface utilisateur pour g√©rer collaborativement le cycle de vie complet d‚Äôun mod√®le MLflow‚Äù"
  },
  {
    "objectID": "slides/fr/index.html#application-1",
    "href": "slides/fr/index.html#application-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 1",
    "text": "Application 1\n\n\n\nIntroduction aux concepts de MLflow\n\n\n\nDans VSCode, ouvrez le notebook situ√© √† l‚Äôemplacement formation-mlops/notebooks/mlflow-introduction.ipynb.\nEx√©cutez le notebook cellule par cellule.\nSi vous avez termin√© plus t√¥t, explorez l‚Äôinterface utilisateur de MLflow et essayez de cr√©er vos propres exp√©rimentations √† partir du code d‚Äôexemple fourni dans le notebook. Par exemple, essayez d‚Äôajouter d‚Äôautres hyperparam√®tres √† la proc√©dure de grid-search."
  },
  {
    "objectID": "slides/fr/index.html#bilan",
    "href": "slides/fr/index.html#bilan",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Bilan",
    "text": "Bilan\n\nMLflow simplifie le suivi de l‚Äôentra√Ænement de mod√®les\n\nGarde trace des exp√©rimentations et de leurs outputs\nInt√©gration simple avec les principaux frameworks de ML\n\nLimites\n\nComment utiliser des frameworks custom (non-nativement int√©gr√©s) ?\nComment passer de l‚Äôexp√©rimentation √† la mise en production ?"
  },
  {
    "objectID": "slides/fr/index.html#contexte-1",
    "href": "slides/fr/index.html#contexte-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Contexte",
    "text": "Contexte\n\nCode APE\n\nNomenclature statistique des Activit√©s √©conomiques dans la Communaut√© Europ√©enne\nStructure hierarchique (NACE) avec 5 niveaux et 732 codes\n\nA l‚ÄôInsee, pr√©c√©demment classifi√© par un algorithme bas√© sur des r√®gles de d√©cisions\nProbl√©matique commune √† beaucoup d‚ÄôInstituts nationaux de statistique"
  },
  {
    "objectID": "slides/fr/index.html#le-mod√®le-fasttext",
    "href": "slides/fr/index.html#le-mod√®le-fasttext",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Le mod√®le FastText",
    "text": "Le mod√®le FastText\n\nMod√®le ‚Äúsac de n-gram‚Äù : plongements lexicaux pour les mots mais aussi pour les n-gram de mots et de caract√®res\nUn mod√®le tr√®s simple et rapide\n\nOVA: One vs.¬†All"
  },
  {
    "objectID": "slides/fr/index.html#donn√©es-utilis√©es",
    "href": "slides/fr/index.html#donn√©es-utilis√©es",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Donn√©es utilis√©es",
    "text": "Donn√©es utilis√©es\n\nDonn√©esBrutesPr√©-trait√©e\n\n\n\nUn cas d‚Äôutilisation simple avec seulement 2 variables :\n\nDescription textuelle de l‚Äôactivit√© - text\nCode APE vrai labelis√© par le moteur de r√®gles ‚Äì nace (732 modalit√©s)\n\nPr√©traitements standards :\n\nPassage en minuscules\nSuppression de la ponctuation\nSuppression des nombres\nSuppression des stop words\nRacinisation (stemming)\n‚Ä¶\n\n\n\n\n\nviewof table_data = Inputs.table(transpose(data_raw), {\n    rows: 22\n})\n\n\n\n\n\n\n\n\n\nviewof table_data_prepro = Inputs.table(transpose(data_prepro), {\n    rows: 22\n})"
  },
  {
    "objectID": "slides/fr/index.html#mlflow-avec-framework-non-standard",
    "href": "slides/fr/index.html#mlflow-avec-framework-non-standard",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "MLflow avec framework non standard",
    "text": "MLflow avec framework non standard\n\n\nFacile d‚Äôutilisation avec une grande vari√©t√© de framework de machine learning (scikit-learn, Keras, Pytorch‚Ä¶)\n\n\n\nmlflow.sklearn.log_model(pipe_rf, \"model\")\n\nmlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")\ny_train_pred = model.predict(X_train)\n\n\n\nQue se passe-t-il si nous avons besoin d‚Äôune plus grande flexibilit√©, par exemple, pour utiliser un framework personnalis√©?\n\n\n\n\nPossibilit√© de suivre, enregistrer et d√©ployer son propre mod√®le"
  },
  {
    "objectID": "slides/fr/index.html#mlflow-avec-framework-non-standard-1",
    "href": "slides/fr/index.html#mlflow-avec-framework-non-standard-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "MLflow avec framework non standard",
    "text": "MLflow avec framework non standard\n\n\nIl y a 2 principales diff√©rences lorsque vous utilisez votre propre framework:\n\nL‚Äôenregistrement des param√®tres, des m√©triques et des artefacts\nL‚Äôencapsulation de votre mod√®le personalis√© afin que MLflow puisse le servir\n\n\n\n\n# Define a custom model\nclass MyModel(mlflow.pyfunc.PythonModel):\n\n    def load_context(self, context):\n        self.my_model.load_model(context.artifacts[\"my_model\"])\n\n    def predict(self, context, model_input):\n        return self.my_model.predict(model_input)"
  },
  {
    "objectID": "slides/fr/index.html#de-lexp√©rimentation-√†-la-production",
    "href": "slides/fr/index.html#de-lexp√©rimentation-√†-la-production",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "De l‚Äôexp√©rimentation √† la production",
    "text": "De l‚Äôexp√©rimentation √† la production\n\nLes notebooks ne sont pas adapt√©s pour une mise en production de mod√®les ML :\n\nPotentiel limit√© d‚Äôautomatisation des pipelines ML.\nWorkflows peu clairs et peu reproductible.\nLimite la collaboration et le contr√¥le de version entre les membres de l‚Äô√©quipe.\nModularit√© insuffisante pour g√©rer des composants ML complexe."
  },
  {
    "objectID": "slides/fr/index.html#application-2",
    "href": "slides/fr/index.html#application-2",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPartie 1 : Utilisation d‚Äôun mod√®le personnalis√©\n\n\n\nTous les scripts li√©s √† notre mod√®le personnalis√© sont stock√©s dans le dossier src. Consultez-les. En particulier, le script train.py est responsable de l‚Äôentra√Ænement du mod√®le. Quelles sont les principales diff√©rences avec l‚Äôapplication 1 ?\nPourquoi pouvons-nous dire que le mod√®le MLflow int√®gre le preprocessing ?"
  },
  {
    "objectID": "slides/fr/index.html#application-2-1",
    "href": "slides/fr/index.html#application-2-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPartie 2 : Des notebooks √† un projet de type package\n\n\n\nLe script train.py est √©galement responsable du logging des exp√©rimentations dans MLFlow. Notez la mani√®re dont les param√®tres de chaque exp√©rimentation vont √™tre pass√©s √† la fonction d‚Äôentra√Ænement √† l‚Äôappel du script.\nAfin de rendre la proc√©dure d‚Äôentra√Ænement d‚Äôun mod√®le plus reproductible, MLFlow met √† disposition la commande mlflow run. Le fichier MLproject sp√©cifie la commande et les param√®tres qui vont lui √™tre pass√©es. Inspectez ce fichier.\nEx√©cutez un entra√Ænement du mod√®le √† l‚Äôaide de MLFlow. Pour ce faire, ouvrez un terminal ( -&gt; Terminal -&gt; New Terminal) et ex√©cutez la commande suivante :\nexport MLFLOW_EXPERIMENT_NAME=\"nace-prediction\"\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n    -P remote_server_uri=$MLFLOW_TRACKING_URI \\\n    -P experiment_name=$MLFLOW_EXPERIMENT_NAME\nDans l‚Äôinterface de MLflow, examinez les r√©sultats de votre ex√©cution pr√©c√©dente :\n\nExperiments -&gt; nace-prediction -&gt; &lt;nom_run&gt;\n\nVous avez entra√Æn√© le mod√®le avec certains param√®tres par d√©faut. Dans le fichier MLproject, v√©rifiez les param√®tres disponibles. R√©-entra√Ænez un mod√®le avec diff√©rents param√®tres (par exemple, dim = 25).\n\n\n\nCliquez pour voir la commande \n\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n    -P remote_server_uri=$MLFLOW_TRACKING_URI \\\n    -P experiment_name=$MLFLOW_EXPERIMENT_NAME \\\n    -P dim=25\n\n\nDans MLflow, comparez les 2 mod√®les en tra√ßant la m√©trique accuracy par rapport √† un param√®tre que vous avez modifi√© (par exemple dim)\n\nS√©lectionnez les 2 exp√©riences -&gt; Compare -&gt; Scatter Plot -&gt; Select your X and Y axis\n\nEnregistrez le mod√®le avec la meilleure accuracy en tant que fasttext pour le rendre facilement interrogeable depuis Python."
  },
  {
    "objectID": "slides/fr/index.html#application-2-2",
    "href": "slides/fr/index.html#application-2-2",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPartie 3 : Requ√™tage du mod√®le entra√Æn√© en local\n\n\n\nCr√©ez un script predict_mlflow.py dans le dossier src du projet. Ce script doit :\n\nCharger la version 1 du mod√®le fasttext\nUtiliser le mod√®le pour pr√©dire les codes NACE d‚Äôune liste donn√©e de descriptions d‚Äôactivit√© (par exemple, [\"vendeur d'huitres\", \"boulanger\"]).\n\n\nüí° N‚Äôoubliez pas de lire la documentation de la fonction predict() de la classe personnalis√©e (src/fasttext_wrapper.py) pour comprendre le format attendu des entr√©es !\n\n\nCliquez pour voir le contenu du script \n\n\n\npredict_mlflow.py\n\nimport mlflow\n\nmodel_name = \"fasttext\"\nversion = 1\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f\"models:/{model_name}/{version}\"\n)\n\nlist_libs = [\"vendeur d'huitres\", \"boulanger\"]\n\nresults = model.predict(list_libs, params={\"k\": 1})\nprint(results)\n\n\n\nEx√©cutez votre script predict_mlflow.py.\n\n\n\nCliquez pour voir la commande \n\npython formation-mlops/src/predict_mlflow.py\n\n\nAssurez-vous que les deux descriptions suivantes donnent la m√™me pr√©diction principale : \"COIFFEUR\" et \"coiffeur, & 98789\".\nModifiez la valeur du param√®tre k et essayez de comprendre comment la structure de la sortie a chang√© en cons√©quence."
  },
  {
    "objectID": "slides/fr/index.html#bilan-1",
    "href": "slides/fr/index.html#bilan-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Bilan",
    "text": "Bilan\n\nMLflow est polyvalent\n\nUtilisation dee frameworks custom (modulo une classe ‚Äúinterface‚Äù)\nIndustrialisation de l‚Äôentra√Ænement (fichier MLproject)\nRequ√™tage simple des mod√®les entra√Æn√©s et stock√©s\n\nLimite : le mod√®le entra√Æn√© n‚Äôest pas accessible\n\nRequ√™tage simplifi√©‚Ä¶ mais format non-pertinent pour tous les utilisateurs\nLe mod√®le n‚Äôest pas d√©ploy√©"
  },
  {
    "objectID": "slides/fr/index.html#questions-essentielles",
    "href": "slides/fr/index.html#questions-essentielles",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Questions essentielles",
    "text": "Questions essentielles\n\nUne fois qu‚Äôun mod√®le de machine learning a √©t√© d√©velopp√©, il doit servir ses utilisateurs finaux.\n\nQuel format pertinent pour rendre accessible aux utilisateurs finaux ?\nTraitement par lots (batch) par rapport au traitement en ligne (online)\nQuelle infrastructure pour le d√©ploiement ?"
  },
  {
    "objectID": "slides/fr/index.html#configuration-envisag√©e",
    "href": "slides/fr/index.html#configuration-envisag√©e",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Configuration envisag√©e",
    "text": "Configuration envisag√©e\n\nLe mod√®le peut servir diverses applications\n\nRendre le mod√®le accessible via une API\n\nTraitement en ligne (online serving)\n\nLes applications client envoient une requ√™te √† l‚ÄôAPI et re√ßoivent une r√©ponse rapide\n\nInfrastructure de d√©ploiement : cluster Kubernetes"
  },
  {
    "objectID": "slides/fr/index.html#exposer-un-mod√®le-via-une-api",
    "href": "slides/fr/index.html#exposer-un-mod√®le-via-une-api",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Exposer un mod√®le via une API",
    "text": "Exposer un mod√®le via une API"
  },
  {
    "objectID": "slides/fr/index.html#pourquoi-exposer-un-mod√®le-via-une-api-rest",
    "href": "slides/fr/index.html#pourquoi-exposer-un-mod√®le-via-une-api-rest",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Pourquoi exposer un mod√®le via une API REST ?",
    "text": "Pourquoi exposer un mod√®le via une API REST ?\n\nSimplicit√© : porte d‚Äôentr√©e unique qui cache la complexit√© sous-jacente du mod√®le\nStandardisation : requ√™tes HTTP -&gt; agnostique au langage de programmation utilis√©\nPassage √† l‚Äô√©chelle : adaptation √† la charge de requ√™tes concurrentes\nModularit√© : s√©paration de la gestion du mod√®le et de sa mise √† disposition"
  },
  {
    "objectID": "slides/fr/index.html#exposer-un-mod√®le-via-une-api-1",
    "href": "slides/fr/index.html#exposer-un-mod√®le-via-une-api-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Exposer un mod√®le via une API",
    "text": "Exposer un mod√®le via une API"
  },
  {
    "objectID": "slides/fr/index.html#ex√©cuter-une-api-dans-un-conteneur",
    "href": "slides/fr/index.html#ex√©cuter-une-api-dans-un-conteneur",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Ex√©cuter une API dans un conteneur",
    "text": "Ex√©cuter une API dans un conteneur\n\nConteneur : environnement autonome et isol√© qui encapsule le mod√®le, l‚ÄôAPI et leurs d√©pendances\nAvantages :\n\nPortabilit√©\nScalabilit√© pour distribuer le mod√®le de mani√®re efficace\n\nPr√©-requis technique pour d√©ployer sur Kubernetes"
  },
  {
    "objectID": "slides/fr/index.html#d√©ploiement-dune-api-sur-kubernetes",
    "href": "slides/fr/index.html#d√©ploiement-dune-api-sur-kubernetes",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "D√©ploiement d‚Äôune API sur Kubernetes",
    "text": "D√©ploiement d‚Äôune API sur Kubernetes"
  },
  {
    "objectID": "slides/fr/index.html#application-3",
    "href": "slides/fr/index.html#application-3",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPartie 1 : exposer localement un mod√®le de ML en tant qu‚ÄôAPI\n\n\n\nNous avons construit une API REST tr√®s simpliste √† l‚Äôaide de FastAPI. Tous les fichiers sous-jacents se trouvent dans le dossier app. Consultez-les.\nD√©ployez l‚ÄôAPI localement en lan√ßant les commandes suivantes dans un terminal :\n\nexport MLFLOW_MODEL_NAME=\"fasttext\"\nexport MLFLOW_MODEL_VERSION=1\nuvicorn app.main:app --root-path /proxy/8000\n\nOuvrez la page de l‚ÄôAPI √† l‚Äôaide du bouton propos√© par VSCode.\nAffichez la documentation de votre API en ajoutant /docs √† votre URL.\nTestez votre API !"
  },
  {
    "objectID": "slides/fr/index.html#application-3-1",
    "href": "slides/fr/index.html#application-3-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPartie 2 : d√©ploiement manuel d‚Äôun mod√®le de ML en tant qu‚ÄôAPI\n\n\n\nOuvrez le Dockerfile pour voir comment l‚Äôimage est construite. L‚Äôimage est automatiquement reconstruite et publi√©e via Github Actions, si vous √™tes int√©ress√©, jetez un coup d‚Äô≈ìil √† .github/workflows/build_image.yml. Dans le cadre de cette formation, nous allons tous utiliser cette m√™me image.\nOuvrez le fichier kubernetes/deployment.yml et modifiez les lignes surlign√©es comme suit :\n\n\n\ndeployment.yml\n\ncontainers:\n- name: api\n    image: inseefrlab/formation-mlops-api:main\n    imagePullPolicy: Always\n    env:\n    - name: MLFLOW_TRACKING_URI\n        value: https://user-&lt;namespace&gt;-&lt;pod_id&gt;.user.lab.sspcloud.fr\n    - name: MLFLOW_MODEL_NAME\n        value: fasttext\n    - name: MLFLOW_MODEL_VERSION\n        value: \"1\"\n\n\nOuvrez le fichier kubernetes/ingress.yml et modifiez (deux fois) l‚ÄôURL du point de terminaison de l‚ÄôAPI pour qu‚Äôelle soit de la forme &lt;votre_pr√©nom&gt;-&lt;votre_nom&gt;-api.lab.sspcloud.fr.\nAppliquez les trois contrats Kubernetes contenus dans le dossier kubernetes/ dans un terminal pour d√©ployer l‚ÄôAPI\n\nkubectl apply -f formation-mlops/kubernetes/\n\nAcc√©dez √† votre API en utilisant l‚ÄôURL d√©finie dans votre fichier ingress.yml.\nR√©entrainez un nouveau mod√®le et d√©ployez ce nouveau mod√®le dans votre API\n\n\n\nCliquez pour voir les √©tapes \n\n\nEntrainez un mod√®le.\nEnregistrez le mod√®le dans MLflow.\nAjustez votre variable d‚Äôenvironnement MLFLOW_MODEL_NAME ou MLFLOW_MODEL_VERSION (si vous n‚Äôavez pas modifi√© le nom du mod√®le) dans le fichier deployment.yml.\nAppliquez les nouveaux contrats Kubernetes pour mettre √† jour l‚ÄôAPI\n\nkubectl apply -f formation-mlops/kubernetes/\n\nRafra√Æchissez votre API et v√©rifiez sur la page d‚Äôaccueil qu‚Äôelle est d√©sormais bas√©e sur la nouvelle version du mod√®le."
  },
  {
    "objectID": "slides/fr/index.html#application-3-2",
    "href": "slides/fr/index.html#application-3-2",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPartie 3 : d√©ploiement continu d‚Äôun mod√®le de ML en tant qu‚ÄôAPI\n\n\n‚ö†Ô∏è Les pr√©c√©dentes applications doivent avoir √©t√© r√©alis√©es avec l‚Äôoption Git pour pouvoir suivre celle-ci.\nPr√©cedement, vous avez d√©ploy√© votre mod√®le manuellement. Gr√¢ce √† ArgoCD il est possible de d√©ployer un mod√®le de mani√®re continu, ainsi chaque modification d‚Äôun fichier pr√©sent dans le dossier kubernetes/ va entrainer le red√©ploiement automatique en se synchronisation avec votre d√©p√¥t Github. Pour vous en convaincre, suivez les √©tapes ci dessous :\n\nSupprimez le d√©ploiement manuel de l‚Äôapplication pr√©c√©dente pour √©viter que les ressources Kubernetes ne se superposent :\n\nkubectl delete -f formation-mlops/kubernetes/\n\nLancez un service ArgoCD en cliquant sur cette URL. Ouvrez le service, saisissez l‚Äôidentifiant (admin) et le mot de passe du service.\nFaite un commit des changements effectu√©s et pousser vers votre d√©p√¥t Github.\nOuvrez le template argocd/template-argocd.yml et modifiez les lignes surlign√©es :\n\n\n\ntemplate-argocd.yml\n\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/&lt;your-github-id&gt;/formation-mlops.git\n    targetRevision: HEAD\n    path: kubernetes\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: &lt;your-namespace&gt;\n\n\nDans ArgoCD, cliquez sur New App puis Edit as a YAML. Copiez-collez le contenu de argocd/template-argocd.yml et cliquez sur Create.\nAcc√©dez √† votre API en utilisant l‚ÄôURL d√©finie dans votre fichier ingress.yml.\nAffichez la documentation de votre API en ajoutant /docs √† votre URL.\nTestez votre API !\nR√©entrainez un nouveau mod√®le et d√©ployez automatiquement ce nouveau mod√®le dans votre API\n\n\n\nCliquez pour voir les √©tapes \n\n\nEntrainez un mod√®le.\nEnregistrez le mod√®le dans MLflow.\nAjustez votre variable d‚Äôenvironnement MLFLOW_MODEL_NAME ou MLFLOW_MODEL_VERSION (si vous n‚Äôavez pas modifi√© le nom du mod√®le) dans le fichier deployment.yml.\nFaite un commit de ces changements et poussez les sur votre d√©p√¥t Github.\nPatientez 5 minutes qu‚ÄôArgoCD synchronise automatiquement les changements depuis votre d√©p√¥t Github ou bien forcez la synchronisation. Rafra√Æchissez votre API et v√©rifiez sur la page d‚Äôaccueil qu‚Äôelle est d√©sormais bas√©e sur la nouvelle version du mod√®le."
  },
  {
    "objectID": "slides/fr/index.html#application-3-3",
    "href": "slides/fr/index.html#application-3-3",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPartie 4 : requ√™ter votre mod√®le d√©ploy√©\n\n\n\nCr√©ez un fichier predict_api.py. Ce script doit :\n\nLire le fichier parquet disponible √† l‚Äôadresse suivante :\n\nhttps://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet\n\nEffectuer des requ√™tes √† votre API pour chaque libell√© pr√©sent dans le fichier parquet.\nAfficher le r√©sultats des pr√©dictions\n\n\n\n\nCliquez pour voir le contenu du script \n\n\n\npredict_api.py\n\nimport pandas as pd\nimport requests\n\n\n# Fonction pour effectuer la requ√™te √† l'API\ndef make_prediction(api_url: str, description: str):\n    params = {\"description\": description, \"nb_echoes_max\": 2}\n    response = requests.get(api_url, params=params)\n    return response.json()\n\n\n# URL des donn√©es\ndata_path = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet\"\n\n# Charge le fichier Parquet dans un DataFrame pandas\ndf = pd.read_parquet(data_path)\n\n# URL de l'API\napi_url = \"https://&lt;your_firstname&gt;-&lt;your_lastname&gt;-api.lab.sspcloud.fr/predict\"\n\n# Effectue les requ√™tes\nresponses = df[\"text\"].apply(lambda x: make_prediction(api_url, x))\n\n# Affiche le DataFrame avec les r√©sultats des pr√©dictions\nprint(pd.merge(df, pd.json_normalize(responses),\n               left_index=True,\n               right_index=True))\n\n\n\nEx√©cutez votre script predict_api.py.\n\n\n\nCliquez pour voir la commande \n\npython formation-mlops/src/predict_api.py\n\n\nDans ArgoCD, ouvrez votre application puis cliquez sur votre pod qui doit commencer par \"codification-api-...\". Observez les logs.\nQuelles informations d√©tenez-vous ? Est-ce suffisant ?\n\n\n\n\n\n\n\nImportant\n\n\nNous avons ici r√©alis√© une succession de requ√™tes GET car nous avons un seul point d‚Äôentr√©e vers notre API. Pour r√©aliser des requ√™tes en batch il est pr√©f√©rable de r√©aliser des requ√™tes POST."
  },
  {
    "objectID": "slides/fr/index.html#bilan-2",
    "href": "slides/fr/index.html#bilan-2",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Bilan",
    "text": "Bilan"
  },
  {
    "objectID": "slides/fr/index.html#cycle-de-vie-dun-mod√®le-ml-en-production",
    "href": "slides/fr/index.html#cycle-de-vie-dun-mod√®le-ml-en-production",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Cycle de vie d‚Äôun mod√®le ML en production",
    "text": "Cycle de vie d‚Äôun mod√®le ML en production"
  },
  {
    "objectID": "slides/fr/index.html#le-d√©fi-de-la-responsabilit√©",
    "href": "slides/fr/index.html#le-d√©fi-de-la-responsabilit√©",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Le d√©fi de la responsabilit√©",
    "text": "Le d√©fi de la responsabilit√©\n\nLe cycle de vie d‚Äôun mod√®le ML est complexe\nPlusieurs parties prenantes impliqu√©es :\n\nData scientists\nIT/DevOps\nEquipes m√©tiers\n\nExpertises et vocabulaire diff√©rents entre ces parties prenantes\n\n‚û°Ô∏è Communication essentielle entre les √©quipes pour contr√¥ler le mod√®le en production"
  },
  {
    "objectID": "slides/fr/index.html#pourquoi-surveiller-un-mod√®le-en-production",
    "href": "slides/fr/index.html#pourquoi-surveiller-un-mod√®le-en-production",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Pourquoi surveiller un mod√®le en production ?",
    "text": "Pourquoi surveiller un mod√®le en production ?\n\nD√©tecter des donn√©es biais√©es : ad√©quation entre les donn√©es de production et donn√©es d‚Äôentrainement\nAnticiper une instabilit√© du mod√®le : performance du mod√®le stable au fil du temps\nAm√©liorer de mani√®re continue le mod√®le : r√©-entrainements r√©guliers\n\n‚ö†Ô∏è Le mot surveillance d‚Äôune application/mod√®le a des d√©finitions diff√©rentes en fonction de l‚Äô√©quipe o√π l‚Äôon se trouve."
  },
  {
    "objectID": "slides/fr/index.html#surveillance-selon-linformaticien",
    "href": "slides/fr/index.html#surveillance-selon-linformaticien",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Surveillance selon l‚Äôinformaticien",
    "text": "Surveillance selon l‚Äôinformaticien\n\nSurveiller une application est partie int√©grante de l‚Äôapproche DevOps\nContr√¥le technique du mod√®le :\n\nLatence\nM√©moire\nUtilisation disque\n‚Ä¶"
  },
  {
    "objectID": "slides/fr/index.html#surveillance-selon-le-data-scientist",
    "href": "slides/fr/index.html#surveillance-selon-le-data-scientist",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Surveillance selon le data scientist",
    "text": "Surveillance selon le data scientist\n\nSurveiller un mod√®le ML est partie int√©grante de l‚Äôapproche MLOps\nContr√¥le m√©thodologique du mod√®le\nPerformance en temps r√©el du mod√®le souvent impossible, utilisation de proxys :\n\nData drift : la distribution des donn√©es d‚Äôentr√©e change dans le temps\nConcept drift : la relation mod√©lis√©e change dans le temps"
  },
  {
    "objectID": "slides/fr/index.html#comment-surveiller-un-mod√®le-en-production",
    "href": "slides/fr/index.html#comment-surveiller-un-mod√®le-en-production",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Comment surveiller un mod√®le en production ?",
    "text": "Comment surveiller un mod√®le en production ?\n\nInt√©gration de logs dans l‚ÄôAPI\nR√©cup√©ration et mise en forme des logs\nSuivi de m√©triques de ML\nMise en place d‚Äôun syst√®me d‚Äôalertes"
  },
  {
    "objectID": "slides/fr/index.html#application-4",
    "href": "slides/fr/index.html#application-4",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nPartie 1 : Logger des m√©triques m√©tier\n\n\n\nGr√¢ce au package logging, rajoutez des logs √† votre API. Pour chaque requ√™te, affichez le libell√© √† coder ainsi que les r√©ponses renvoy√©es par votre API. Pour cela, modifiez le fichier app/main.py.\n\n\n\nCliquez pour voir les √©tapes √† r√©aliser \n\n\nImportez le package logging :\n\n\n\nmain.py\n\nimport logging\n\n\nD√©finissez la configuration de vos logs avant la d√©finition de votre premier point d‚Äôentr√©e :\n\n\n\nmain.py\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[\n        logging.FileHandler(\"log_file.log\"),\n        logging.StreamHandler(),\n    ],\n)\n\n\nAjoutez une le libell√© et la r√©ponse de l‚ÄôAPI dans vos logs :\n\n\n\nmain.py\n\n# Logging\nlogging.info(f\"{{'Query': {description}, 'Response': {predictions[0]}}}\")\n\n\n\nFaites un commit de vos changements et poussez les sur votre d√©p√¥t distant.\nD√®s lors que vous r√©alisez un changement sur votre API, il est n√©cessaire de la red√©ployer pour que les changements soient effectifs. En th√©orie, il serait n√©cessaire de re-construire une nouvelle image pour notre API contenant les derniers ajustements. Pour simplifier, nous avons d√©j√† construit les deux images avec et sans logs dans l‚ÄôAPI. Jusqu‚Äô√† pr√©sent vous avez utilis√© l‚Äôimage sans logs, red√©ployez votre API en utilisant l‚Äôimage avec les logs dont le tag est logs.\n\n\n\nCliquez pour voir les √©tapes √† r√©aliser \n\n\nDans le fichier kubernetes/deployment.yml, remplacer le tag no-logs par le tag logs :\n\n\n\ndeployment.yml\n\ntemplate:\n  metadata:\n    labels:\n      app: codification-api\n  spec:\n    containers:\n      - name: api\n        image: inseefrlab/formation-mlops:logs\n        imagePullPolicy: Always\n\n\nFaites un commit de vos changements et poussez les sur votre d√©p√¥t distant.\nPatientez 5 minutes qu‚ÄôArgoCD synchronise automatiquement les changements depuis votre d√©p√¥t Github ou bien forcez la synchronisation.\n\n\n\nEx√©cutez votre script predict-api.py.\n\n\n\nCliquez pour voir la commande \n\npython formation-mlops/src/predict-api.py\n\n\nDans ArgoCD, ouvrez votre application puis cliquez sur votre pod qui doit commencer par \"codification-api-...\". Observez les logs."
  },
  {
    "objectID": "slides/fr/index.html#observabilit√©-du-mod√®le-gr√¢ce-√†-un-tableau-de-bord",
    "href": "slides/fr/index.html#observabilit√©-du-mod√®le-gr√¢ce-√†-un-tableau-de-bord",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Observabilit√© du mod√®le gr√¢ce √† un tableau de bord",
    "text": "Observabilit√© du mod√®le gr√¢ce √† un tableau de bord\n\nLes logs de l‚ÄôAPI contiennent maintenant des informations m√©tier\nPour le traitement/stockage des logs : pipeline ETL\nPour analyser le comportement du moteur de codification : cr√©ation d‚Äôun tableau de bord\nSolutions multiples pour le tableau de bord : Grafana, Quarto Dashboards, Apache Superset, ‚Ä¶"
  },
  {
    "objectID": "slides/fr/index.html#un-exemple-de-stack",
    "href": "slides/fr/index.html#un-exemple-de-stack",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Un exemple de stack",
    "text": "Un exemple de stack\n\nETL sous forme d‚Äôun cron job qui parse les logs et les stocke au format .parquet\nUtilisation de DuckDB pour requ√™ter les fichiers .parquet\n‚Ä¶ et cr√©er les composants d‚Äôun Quarto Dashboards\nLe tableau de bord est un site statique √† actualiser tous les jours par exemple"
  },
  {
    "objectID": "slides/fr/index.html#un-exemple-de-stack-1",
    "href": "slides/fr/index.html#un-exemple-de-stack-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Un exemple de stack",
    "text": "Un exemple de stack"
  },
  {
    "objectID": "slides/fr/index.html#application-4-1",
    "href": "slides/fr/index.html#application-4-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nPartie 2 : Cr√©ation d‚Äôun tableau de bord de monitoring\n\n\n\nNous allons utiliser Quarto Dashboards. Ouvrez le fichier dashboard/index.qmd et inspectez le code. Pour r√©cup√©rer les donn√©es n√©cessaires √† la cr√©ation du tableau de bord, on utilise un SGBD serverless : DuckDB. DuckDB nous permet de faire des requ√™tes SQL sur un fichier .parquet contenant des logs pars√©s. Ce fichier contient une ligne par pr√©diction, avec les variables timestamp, text, prediction_1, proba_1, prediction_2 et proba_2.\nPour visualiser le tableau de bord, entrez les commandes suivantes dans un Terminal depuis la racine du projet et cliquez sur le lien g√©n√©r√©.\ncd dashboard\nquarto preview index.qmd\nPour l‚Äôinstant le pourcentage de pr√©dictions avec une probabilit√© sup√©rieure √† 0.8 ne correspond pas √† la r√©alit√©. Modifiez la requ√™te SQL permettant d‚Äôobtenir la variable pct_predictions pour afficher la bonne valeur.\n\n\n\nCliquez pour voir la r√©ponse \n\npct_predictions = duckdb.sql(\n    \"\"\"\n    SELECT 100 * COUNT(*) / COUNT(*)\n    FROM data;\n    \"\"\"\n).fetchall()[0][0]\n\n\nLes deux graphiques situ√©s en bas du tableau de bord ne sont pas corrects non plus. Modifiez la requ√™te SQL permettant d‚Äôobtenir la variable daily_stats pour afficher les bons graphiques.\n\n\n\nCliquez pour voir la r√©ponse \n\ndaily_stats = duckdb.sql(\n    \"\"\"\n    SELECT\n        CAST(timestamp AS DATE) AS date,\n        COUNT(*) AS n_liasses,\n        (\n            COUNT(\n                CASE WHEN data.proba_1 &gt; 0.8 THEN 1 END\n            ) * 100.0 / COUNT(*)\n        ) AS pct_high_proba\n    FROM data\n    GROUP BY CAST(timestamp AS DATE);\n    \"\"\"\n).to_df()\n\nConstatez les changements apport√©s au tableau de bord."
  },
  {
    "objectID": "slides/fr/index.html#bilan-3",
    "href": "slides/fr/index.html#bilan-3",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Bilan",
    "text": "Bilan"
  },
  {
    "objectID": "slides/fr/index.html#entra√Ænement-distribu√©",
    "href": "slides/fr/index.html#entra√Ænement-distribu√©",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Entra√Ænement distribu√©",
    "text": "Entra√Ænement distribu√©\n\nAvec notre configuration, nous pouvons entra√Æner des mod√®les un par un et enregistrer toutes les informations pertinentes sur le serveur MLflow Tracking.\nEt si nous voulions entra√Æner plusieurs mod√®les en m√™me temps, par exemple pour optimiser les hyperparam√®tres ?"
  },
  {
    "objectID": "slides/fr/index.html#automatisation-du-workflow",
    "href": "slides/fr/index.html#automatisation-du-workflow",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Automatisation du workflow",
    "text": "Automatisation du workflow\n\nPrincipes g√©n√©raux :\n\nD√©finir des workflows o√π chaque √©tape du processus est un conteneur (reproductibilit√©).\nMod√©liser les workflows √† plusieurs √©tapes comme une s√©quence de t√¢ches ou comme un graphe acyclique orient√©.\nCela permet d‚Äôex√©cuter facilement en parall√®le des t√¢ches intensives en calcul pour l‚Äôentra√Ænement du mod√®le ou le traitement des donn√©es."
  },
  {
    "objectID": "slides/fr/index.html#argo-workflows",
    "href": "slides/fr/index.html#argo-workflows",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Argo workflows",
    "text": "Argo workflows\n\nUn moteur de workflow populaire pour orchestrer des t√¢ches parall√®les sur Kubernetes.\n\nOpen-source\nContainer-native\nDisponible sur le SSP Cloud"
  },
  {
    "objectID": "slides/fr/index.html#bonjour-le-monde",
    "href": "slides/fr/index.html#bonjour-le-monde",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Bonjour le monde",
    "text": "Bonjour le monde\napiVersion: argoproj.io/v1alpha1\nkind: Workflow                  # nouveau type de sp√©cification k8s\nmetadata:\n  generateName: hello-world-    # nom de la sp√©cification du workflow\nspec:\n  entrypoint: whalesay          # invoque le mod√®le whalesay\n  templates:\n    - name: whalesay            # nom du mod√®le\n      container:\n        image: docker/whalesay\n        command: [ cowsay ]\n        args: [ \"bonjour le monde\" ]"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il",
    "href": "slides/fr/index.html#que-se-passe-t-il",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-1",
    "href": "slides/fr/index.html#que-se-passe-t-il-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-2",
    "href": "slides/fr/index.html#que-se-passe-t-il-2",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#param√®tres",
    "href": "slides/fr/index.html#param√®tres",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Param√®tres",
    "text": "Param√®tres\n\nLes mod√®les peuvent prendre des param√®tres d‚Äôentr√©e\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-parameters-\nspec:\n  entrypoint: whalesay\n  arguments:\n    parameters:\n    - name: message\n      value: bonjour le monde\n\n  templates:\n  - name: whalesay\n    inputs:\n      parameters:\n      - name: message       # d√©claration du param√®tre\n    container:\n      image: docker/whalesay\n      command: [cowsay]\n      args: [\"{{inputs.parameters.message}}\"]"
  },
  {
    "objectID": "slides/fr/index.html#workflows-√†-plusieurs-√©tapes",
    "href": "slides/fr/index.html#workflows-√†-plusieurs-√©tapes",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Workflows √† plusieurs √©tapes",
    "text": "Workflows √† plusieurs √©tapes\n\nLes workflows √† plusieurs √©tapes peuvent √™tre sp√©cifi√©s (steps ou dag)\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: steps-\nspec:\n  entrypoint: hello-hello-hello\n\n  # Cette sp√©cification contient deux mod√®les : hello-hello-hello et whalesay\n  templates:\n  - name: hello-hello-hello\n    # Au lieu d'ex√©cuter uniquement un conteneur\n    # Ce mod√®le a une s√©quence d'√©tapes\n    steps:\n    - - name: hello1            # hello1 est ex√©cut√© avant les √©tapes suivantes\n        template: whalesay\n    - - name: hello2a           # double tiret =&gt; ex√©cut√© apr√®s l'√©tape pr√©c√©dente\n        template: whalesay\n      - name: hello2b           # tiret simple =&gt; ex√©cut√© en parall√®le avec l'√©tape pr√©c√©dente\n        template: whalesay\n  - name: whalesay              # nom du mod√®le\n    container:\n      image: docker/whalesay\n      command: [ cowsay ]\n      args: [ \"bonjour le monde\" ]"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-3",
    "href": "slides/fr/index.html#que-se-passe-t-il-3",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-4",
    "href": "slides/fr/index.html#que-se-passe-t-il-4",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-5",
    "href": "slides/fr/index.html#que-se-passe-t-il-5",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-6",
    "href": "slides/fr/index.html#que-se-passe-t-il-6",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#que-se-passe-t-il-7",
    "href": "slides/fr/index.html#que-se-passe-t-il-7",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Que se passe-t-il ?",
    "text": "Que se passe-t-il ?"
  },
  {
    "objectID": "slides/fr/index.html#autres-applications",
    "href": "slides/fr/index.html#autres-applications",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Autres applications",
    "text": "Autres applications\n\nWorkflow pour tester des mod√®les enregistr√©s, ou des mod√®les pouss√©s en pr√©-production / production.\nLes workflows peuvent √™tre d√©clench√©s automatiquement (via Argo Events, par exemple).\nWorkflows d‚Äôentra√Ænement continue.\nPipelines de machine learning distribu√©s en g√©n√©ral (t√©l√©chargement de donn√©es, traitement, etc.)."
  },
  {
    "objectID": "slides/fr/index.html#autres-applications-1",
    "href": "slides/fr/index.html#autres-applications-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Autres applications",
    "text": "Autres applications"
  },
  {
    "objectID": "slides/fr/index.html#notes",
    "href": "slides/fr/index.html#notes",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Notes",
    "text": "Notes\n\nPython SDK pour Argo Workflows\nPipelines Kubeflow\nCouler : interface unifi√©e pour la construction et la gestion de workflows sur diff√©rents moteurs de workflows\nAutres outils d‚Äôorchestration natifs de Python : Apache Airflow, Metaflow, Prefect"
  },
  {
    "objectID": "slides/fr/index.html#application-5",
    "href": "slides/fr/index.html#application-5",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 5",
    "text": "Application 5\n\n\n\nPartie 1 : introduction √† Argo Workflows\n\n\n\nLancez un service Argo Workflows en cliquant sur cette URL. Ouvrez le service et saisissez le mot de passe du service (soit copi√© automatiquement, soit disponible dans le fichier README du service).\nDans VSCode, cr√©ez un fichier hello_world.yaml √† la racine du projet avec le contenu suivant :\n\n\n\nhello_world.yml\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-\n  labels:\n    workflows.argoproj.io/archive-strategy: \"false\"\n  annotations:\n    workflows.argoproj.io/description: |\n      Ceci est un exemple simple de \"Hello World\".\n      Vous pouvez √©galement l'ex√©cuter en Python : https://couler-proj.github.io/couler/examples/#hello-world\nspec:\n  entrypoint: whalesay\n  templates:\n  - name: whalesay\n    container:\n      image: docker/whalesay:latest\n      command: [cowsay]\n      args: [\"hello world\"]\n\n\nSoumettez le workflow ‚ÄúHello World‚Äù via un terminal dans VSCode :\n\nargo submit formation-mlops/hello_world.yaml\n\nOuvrez l‚Äôinterface utilisateur d‚ÄôArgo Workflows. Trouvez les logs du workflow que vous venez de lancer. Vous devriez voir le logo Docker ."
  },
  {
    "objectID": "slides/fr/index.html#application-5-1",
    "href": "slides/fr/index.html#application-5-1",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Application 5",
    "text": "Application 5\n\n\n\nPartie 2 : distriubtion de l‚Äôoptimisation des hyperparam√®tres\n\n\n\nJetez un coup d‚Äô≈ìil au fichier argo_workflows/workflow.yml. Que pensez-vous qu‚Äôil se passera lorsque nous soumettrons ce flux de travail ?\nModifiez la ligne surlign√©e de la m√™me mani√®re que dans l‚Äôapplication 3.\n\n\n\nworkflow.yml\n\nparameters:\n    # Le serveur de suivi MLflow est responsable de l'enregistrement des hyper-param√®tres et des m√©triques du mod√®le.\n    - name: mlflow-tracking-uri\n    value: https://user-&lt;namespace&gt;-&lt;pod_id&gt;.user.lab.sspcloud.fr\n    - name: mlflow-experiment-name\n    value: nace-prediction\n\n\nSoumettez le flux de travail et observez les t√¢ches s‚Äôex√©cuter en direct dans l‚Äôinterface utilisateur.\n\n\n\nCliquez pour voir la commande \n\nargo submit formation-mlops/argo_workflows/workflow.yml\n\n\nUne fois que toutes les t√¢ches sont termin√©es, visualisez les logs de l‚Äôensemble du flux de travail.\nEnfin, ouvrez l‚Äôinterface utilisateur de MLflow pour v√©rifier ce qui a √©t√© fait."
  },
  {
    "objectID": "slides/fr/index.html#lopportunit√©-dorganisations-plus-continues",
    "href": "slides/fr/index.html#lopportunit√©-dorganisations-plus-continues",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "L‚Äôopportunit√© d‚Äôorganisations plus continues",
    "text": "L‚Äôopportunit√© d‚Äôorganisations plus continues"
  },
  {
    "objectID": "slides/fr/index.html#des-transformations-requises",
    "href": "slides/fr/index.html#des-transformations-requises",
    "title": "Une introduction au MLOps avec MLflow",
    "section": "Des transformations requises",
    "text": "Des transformations requises\n\nDes transformations √† diff√©rents niveaux\n\nOutils techniques\nM√©thodologiques\nOrganisationnels\n\nStrat√©gie : changement incr√©mental\n\nFormation\nApplication √† des projets pilotes"
  },
  {
    "objectID": "slides/en/index.html#who-are-we",
    "href": "slides/en/index.html#who-are-we",
    "title": "An introduction to MLOps with MLflow",
    "section": "Who are we ?",
    "text": "Who are we ?\n\nData scientists at Insee\n\nmethodological and IT innovation teams\nsupport data science projects\n\nContact us\n\nromain.avouac at insee dot fr\nthomas.faria at insee dot fr\ntom.seimandi at insee dot fr"
  },
  {
    "objectID": "slides/en/index.html#context",
    "href": "slides/en/index.html#context",
    "title": "An introduction to MLOps with MLflow",
    "section": "Context",
    "text": "Context\n\nDifficulty of transitioning from experiments to production-grade machine learning systems\nLeverage best practices from software engineering\n\nImprove reproducibility of analysis\nDeploy applications in a scalable way\nMonitor running applications"
  },
  {
    "objectID": "slides/en/index.html#the-devops-approach",
    "href": "slides/en/index.html#the-devops-approach",
    "title": "An introduction to MLOps with MLflow",
    "section": "The DevOps approach",
    "text": "The DevOps approach\n\nUnify development (dev) and system administration (ops)\n\nshorten development time\nmaintain software quality"
  },
  {
    "objectID": "slides/en/index.html#the-mlops-approach",
    "href": "slides/en/index.html#the-mlops-approach",
    "title": "An introduction to MLOps with MLflow",
    "section": "The MLOps approach",
    "text": "The MLOps approach\n\nIntegrate the specificities of machine learning projects\n\nExperimentation\nContinuous improvement"
  },
  {
    "objectID": "slides/en/index.html#mlops-principles",
    "href": "slides/en/index.html#mlops-principles",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLOps : principles",
    "text": "MLOps : principles\n\nReproducibility\nVersioning\nAutomation\nMonitoring\nCollaboration"
  },
  {
    "objectID": "slides/en/index.html#why-mlflow",
    "href": "slides/en/index.html#why-mlflow",
    "title": "An introduction to MLOps with MLflow",
    "section": "Why MLflow ?",
    "text": "Why MLflow ?\n\nMultiple frameworks implement the MLOps principles\nPros of MLflow\n\nOpen-source\nCovers the whole ML lifecycle\nAgnostic to the ML library used\nWe have experience with it"
  },
  {
    "objectID": "slides/en/index.html#training-platform-the-ssp-cloud",
    "href": "slides/en/index.html#training-platform-the-ssp-cloud",
    "title": "An introduction to MLOps with MLflow",
    "section": "Training platform : the SSP Cloud",
    "text": "Training platform : the SSP Cloud\n\nAn open innovation production-like environment\n\nKubernetes cluster\nS3-compatible object storage\nLarge computational resources (including GPUs)\n\nBased on the Onyxia project\n\nUser-friendly interface to launch data science services\nA catalog of services which covers the full lifecycle of data science projects"
  },
  {
    "objectID": "slides/en/index.html#outline",
    "href": "slides/en/index.html#outline",
    "title": "An introduction to MLOps with MLflow",
    "section": "Outline",
    "text": "Outline\n1Ô∏è‚É£ Introduction to MLFlow\n\n2Ô∏è‚É£ A Practical Example: NACE Code Prediction for French companies\n\n\n3Ô∏è‚É£ Deploying a ML model as an API\n\n\n4Ô∏è‚É£ Distributing the hyperparameter optimization\n\n\n5Ô∏è‚É£ Maintenance of a model in production"
  },
  {
    "objectID": "slides/en/index.html#app0",
    "href": "slides/en/index.html#app0",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 0",
    "text": "Application 0\n\nWithout GitWith Git\n\n\n\n\n\nPreparation of the working environment\n\n\n\nCreate an account on the SSP Cloud using your professional mail address\nLaunch a MLflow service by clicking this URL\nLaunch a VSCode-python service by clicking this URL\nOpen the VSCode-python service and input the service password\nYou‚Äôre all set !\n\n\n\n\n\n\n\n\n\nPreparation of the working environment\n\n\n\nIt is assumed that you have a Github account and have already created a token. Fork the training repository by clicking here.\nCreate an account on the SSP Cloud using your professional mail address\nLaunch a MLflow service by clicking this URL\nLaunch a VSCode-python service by clicking this URL\nOpen the VSCode-python service and input the service password\nIn VSCode, open a terminal and clone your forked repository (modify the first two lines):\nGIT_REPO=formation-mlops\nGIT_USERNAME=InseeFrLab\n\ngit clone https://github.com/$GIT_USERNAME/$GIT_REPO.git\ncd $GIT_REPO\nInstall the necessary packages for the training (with uv):\nuv sync\nuv run python -m nltk.downloader stopwords\n```\nYou‚Äôre all set !"
  },
  {
    "objectID": "slides/en/index.html#tracking-server",
    "href": "slides/en/index.html#tracking-server",
    "title": "An introduction to MLOps with MLflow",
    "section": "Tracking server",
    "text": "Tracking server\n\n‚ÄúAn API and UI for logging parameters, code versions, metrics, and artifacts‚Äù"
  },
  {
    "objectID": "slides/en/index.html#projects",
    "href": "slides/en/index.html#projects",
    "title": "An introduction to MLOps with MLflow",
    "section": "Projects",
    "text": "Projects\n\n‚ÄúA standard format for packaging reusable data science code‚Äù"
  },
  {
    "objectID": "slides/en/index.html#models",
    "href": "slides/en/index.html#models",
    "title": "An introduction to MLOps with MLflow",
    "section": "Models",
    "text": "Models\n\n‚ÄúA convention for packaging machine learning models in multiple flavors‚Äù"
  },
  {
    "objectID": "slides/en/index.html#model-registry",
    "href": "slides/en/index.html#model-registry",
    "title": "An introduction to MLOps with MLflow",
    "section": "Model registry",
    "text": "Model registry\n\n‚ÄúA centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an MLflow Model‚Äù"
  },
  {
    "objectID": "slides/en/index.html#application-1",
    "href": "slides/en/index.html#application-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 1",
    "text": "Application 1\n\n\n\nIntroduction to MLflow concepts\n\n\n\nIn VSCode, open the notebook located at formation-mlops/notebooks/mlflow-introduction.ipynb\nExecute the notebook cell by cell.\nIf you are finished early, explore the MLflow UI and try to build your own experiments from the example code provided in the notebook. For example, try to add other hyperparameters in the grid search process."
  },
  {
    "objectID": "slides/en/index.html#summary",
    "href": "slides/en/index.html#summary",
    "title": "An introduction to MLOps with MLflow",
    "section": "Summary",
    "text": "Summary\n\nMLflow simplifies the tracking of model training\n\nKeeps record of experiments and their outputs\nSimple integration with main ML frameworks\n\nLimitations\n\nHow to use custom frameworks (non-natively integrated)?\nHow to move from experimentation to production?"
  },
  {
    "objectID": "slides/en/index.html#context-1",
    "href": "slides/en/index.html#context-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Context",
    "text": "Context\n\nNACE\n\nEuropean standard classification of productive economic activities\nHierarchical structure with 4 levels and 615 codes\n\nAt Insee, previously handled by an outdated rule-based algorithm\nCommon problematic to many National Statistical Institutes"
  },
  {
    "objectID": "slides/en/index.html#fasttext-model",
    "href": "slides/en/index.html#fasttext-model",
    "title": "An introduction to MLOps with MLflow",
    "section": "FastText model",
    "text": "FastText model\n\n‚ÄúBag of n-gram model‚Äù : embeddings for words but also n-gram of words and characters\nVery simple and fast model\n\nOVA: One vs.¬†All"
  },
  {
    "objectID": "slides/en/index.html#data-used",
    "href": "slides/en/index.html#data-used",
    "title": "An introduction to MLOps with MLflow",
    "section": "Data used",
    "text": "Data used\n\nSlideRawPreprocessed\n\n\n\nA simple use-case with only 2 variables:\n\nTextual description of the activity ‚Äì text\nTrue NACE code labelised by the rule-based engine ‚Äì nace (732 modalities)\n\nStandard preprocessing:\n\nlowercasing\npunctuation removal\nnumber removal\nstopwords removal\nstemming\n‚Ä¶\n\n\n\n\n\nviewof table_data = Inputs.table(transpose(data_raw), {\n    rows: 22\n})\n\n\n\n\n\n\n\n\n\nviewof table_data_prepro = Inputs.table(transpose(data_prepro), {\n    rows: 22\n})"
  },
  {
    "objectID": "slides/en/index.html#mlflow-with-a-non-standard-framework",
    "href": "slides/en/index.html#mlflow-with-a-non-standard-framework",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLflow with a non standard framework",
    "text": "MLflow with a non standard framework\n\n\nEasy to use with a variety of machine learning frameworks (scikit-learn, Keras, Pytorch‚Ä¶)\n\n\n\nmlflow.sklearn.log_model(pipe_rf, \"model\")\n\nmlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")\ny_train_pred = model.predict(X_train)\n\n\n\nWhat if we require greater flexibility, e.g.¬†to use a custom framework?\n\n\n\n\nPossibility to track , register and deliver your own model"
  },
  {
    "objectID": "slides/en/index.html#mlflow-with-a-non-standard-framework-1",
    "href": "slides/en/index.html#mlflow-with-a-non-standard-framework-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLflow with a non standard framework",
    "text": "MLflow with a non standard framework\n\n\nThere are 2 main differences when using your own framework:\n\nlogging of parameters, metrics and artifacts\nwrapping of your custom model so that MLflow can serve it\n\n\n\n\n# Define a custom model\nclass MyModel(mlflow.pyfunc.PythonModel):\n\n    def load_context(self, context):\n        self.my_model.load_model(context.artifacts[\"my_model\"])\n\n    def predict(self, context, model_input):\n        return self.my_model.predict(model_input)"
  },
  {
    "objectID": "slides/en/index.html#from-experiment-towards-production",
    "href": "slides/en/index.html#from-experiment-towards-production",
    "title": "An introduction to MLOps with MLflow",
    "section": "From experiment towards production",
    "text": "From experiment towards production\n\nNotebooks are not suitable to build production-grade ML systems:\n\nLimited potential for automation of ML pipelines.\nLack of clear and reproducible workflows.\nHinders collaboration and versioning among team members.\nInsufficient modularity for managing complex ML components."
  },
  {
    "objectID": "slides/en/index.html#application-2",
    "href": "slides/en/index.html#application-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPart 1: Using a custom model\n\n\n\nAll scripts related to our custom model are stored in the src folder. Check them out. In particular, the train.py script is responsible for training the model. What are the main differences compared to application 1?\nWhy can we say that the MLflow model integrates preprocessing?"
  },
  {
    "objectID": "slides/en/index.html#application-2-1",
    "href": "slides/en/index.html#application-2-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPart 2 : From notebooks to a package-like project\n\n\n\nThe train.py script is also responsible for logging experiments in MLFlow. Note how the parameters of each experiment are passed to the training function when the script is called.\nTo make the model training procedure more reproducible, MLFlow provides the mlflow run command. The MLproject file specifies the command and parameters that will be passed to it. Inspect this file.\nRun a model training using MLFlow. To do this, open a terminal ( -&gt; Terminal -&gt; New Terminal) and execute the following command:\nexport MLFLOW_EXPERIMENT_NAME=\"nace-prediction\"\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n    -P remote_server_uri=$MLFLOW_TRACKING_URI \\\n    -P experiment_name=$MLFLOW_EXPERIMENT_NAME\nIn the MLflow interface, examine the results of your previous run:\n\nExperiments -&gt; nace-prediction -&gt; &lt;run_name&gt;\n\nYou trained the model with certain default parameters. In the MLproject file, check the available parameters. Retrain a model with different parameters (e.g., dim = 25).\n\n\n\nClick to see the command \n\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n    -P remote_server_uri=$MLFLOW_TRACKING_URI \\\n    -P experiment_name=$MLFLOW_EXPERIMENT_NAME \\\n    -P dim=25\n\n\nIn MLflow, compare the 2 models by plotting the accuracy against one parameter you have changed (i.e.¬†dim)\n\nSelect the 2 runs -&gt; Compare -&gt; Scatter Plot -&gt; Select your X and Y axis\n\nSave the model with the best accuracy as fasttext to make it easily queryable from Python."
  },
  {
    "objectID": "slides/en/index.html#application-2-2",
    "href": "slides/en/index.html#application-2-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\nPart 3: Querying the locally trained model\n\n\n\nCreate a script predict_mlflow.py in the src folder of the project. This script should:\n\nLoad version 1 of the fasttext model\nUse the model to predict NACE codes for a given list of activity descriptions (e.g., [\"vendeur d'huitres\", \"boulanger\"]).\n\n\nüí° Don‚Äôt forget to read the documentation of the predict() function from the custom class (src/fasttext_wrapper.py) to understand the expected input format!\n\n\nClick to see the script content \n\n\n\npredict_mlflow.py\n\nimport mlflow\n\nmodel_name = \"fasttext\"\nversion = 1\n\nmodel = mlflow.pyfunc.load_model(\n    model_uri=f\"models:/{model_name}/{version}\"\n)\n\nlist_libs = [\"vendeur d'huitres\", \"boulanger\"]\n\nresults = model.predict(list_libs, params={\"k\": 1})\nprint(results)\n\n\n\nRun your predict_mlflow.py script.\n\n\n\nClick to see the command \n\npython formation-mlops/src/predict_mlflow.py\n\n\nEnsure that the following two descriptions give the same main prediction: \"COIFFEUR\" et \"coiffeur, & 98789\".\nChange the value of the k parameter and try to understand how the output structure has changed accordingly."
  },
  {
    "objectID": "slides/en/index.html#summary-1",
    "href": "slides/en/index.html#summary-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Summary",
    "text": "Summary\n\nMLflow is versatile\n\nUse of custom frameworks (with a ‚Äúinterface‚Äù class)\nIndustrialization of training (file MLproject)\nSimple querying of trained and stored models\n\nLimitation: the trained model is not accessible\n\nSimplified querying‚Ä¶ but irrelevant format for all users\nThe model is not deployed"
  },
  {
    "objectID": "slides/en/index.html#essential-questions",
    "href": "slides/en/index.html#essential-questions",
    "title": "An introduction to MLOps with MLflow",
    "section": "Essential questions",
    "text": "Essential questions\n\nOnce a ML model has been developed, it must be deployed to serve its end users\n\nWhich production infrastructure ?\nWho are the end users ?\nBatch serving vs.¬†online serving"
  },
  {
    "objectID": "slides/en/index.html#envisioned-configuration",
    "href": "slides/en/index.html#envisioned-configuration",
    "title": "An introduction to MLOps with MLflow",
    "section": "Envisioned configuration",
    "text": "Envisioned configuration\n\nThe model might serve various applications\n\nMake the model accessible via an API\n\nOnline serving\n\nClient applications send a request to the API and get a fast response\n\nProduction infrastructure : Kubernetes cluster"
  },
  {
    "objectID": "slides/en/index.html#exposing-a-model-through-an-api",
    "href": "slides/en/index.html#exposing-a-model-through-an-api",
    "title": "An introduction to MLOps with MLflow",
    "section": "Exposing a model through an API",
    "text": "Exposing a model through an API"
  },
  {
    "objectID": "slides/en/index.html#why-expose-a-model-via-a-rest-api",
    "href": "slides/en/index.html#why-expose-a-model-via-a-rest-api",
    "title": "An introduction to MLOps with MLflow",
    "section": "Why expose a model via a REST API?",
    "text": "Why expose a model via a REST API?\n\nSimplicity: single entry point that hides the underlying complexity of the model\nStandardization: HTTP requests -&gt; agnostic to the programming language used\nScalability: adapts to the load of concurrent requests\nModularity: separation of model management and its availability"
  },
  {
    "objectID": "slides/en/index.html#exposing-a-model-through-an-api-1",
    "href": "slides/en/index.html#exposing-a-model-through-an-api-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Exposing a model through an API",
    "text": "Exposing a model through an API"
  },
  {
    "objectID": "slides/en/index.html#run-the-api-in-a-container",
    "href": "slides/en/index.html#run-the-api-in-a-container",
    "title": "An introduction to MLOps with MLflow",
    "section": "Run the API in a container",
    "text": "Run the API in a container\n\nContainer: self-contained and isolated environment that encapsulates the model, its dependencies and the API code\nAdvantages:\n\nPortability\nScalability to efficiently distribute the model\n\nTechnical prerequisites for deploying on Kubernetes"
  },
  {
    "objectID": "slides/en/index.html#deploying-an-api-on-kubernetes",
    "href": "slides/en/index.html#deploying-an-api-on-kubernetes",
    "title": "An introduction to MLOps with MLflow",
    "section": "Deploying an API on Kubernetes",
    "text": "Deploying an API on Kubernetes"
  },
  {
    "objectID": "slides/en/index.html#application-3",
    "href": "slides/en/index.html#application-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPart 1: Exposing a ML model locally as an API\n\n\n\nWe constructed a very simplistic Rest API using FastAPI. All underlying files are in the app folder. Check them.\nDeploy the API locally by running the following commands in a terminal:\n\nexport MLFLOW_MODEL_NAME=\"fasttext\"\nexport MLFLOW_MODEL_VERSION=1\nuvicorn app.main:app --root-path /proxy/8000\n\nOpen the API page using the button provided by VSCode.\nDisplay your API documentation by adding /docs to your URL.\nTest your API!"
  },
  {
    "objectID": "slides/en/index.html#application-3-1",
    "href": "slides/en/index.html#application-3-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPart 2 : Deploying manually a machine-learning model as an API\n\n\n\nOpen the Dockerfile to see how the image is built. The image is automatically rebuilt and published via Github Actions, if interested have a look to .github/workflows/build_image.yml. Dans le cadre de cette formation, nous allons tous utiliser cette m√™me image.\nOpen the file kubernetes/deployment.yml and modify the highlighted lines accordingly:\n\n\n\ndeployment.yml\n\ncontainers:\n- name: api\n    image: inseefrlab/formation-mlops-api:main\n    imagePullPolicy: Always\n    env:\n    - name: MLFLOW_TRACKING_URI\n        value: https://user-&lt;namespace&gt;-&lt;pod_id&gt;.user.lab.sspcloud.fr\n    - name: MLFLOW_MODEL_NAME\n        value: fasttext\n    - name: MLFLOW_MODEL_VERSION\n        value: \"1\"\n\n\nOpen the file kubernetes/ingress.yml and modify (two times) the URL of the API endpoint to be of the form &lt;your_firstname&gt;-&lt;your_lastname&gt;-api.lab.sspcloud.fr\nApply the three Kubernetes contracts contained in the kubernetes/ folder in a terminal to deploy the API\n\nkubectl apply -f formation-mlops/kubernetes/\n\nReach your API using the URL defined in your ingress.yml file\nRe-train a new model and deploy this new model in your API\n\n\n\nCliquez pour voir les √©tapes \n\n\nTrain a model\nRegister the model in MLflow\nAdjust your MLFLOW_MODEL_NAME or MLFLOW_MODEL_VERSION (if you didn‚Äôt modify the model name) environment variable in the deployment.yml file\nApply the new Kubernetes contracts to update the API\n\nkubectl apply -f formation-mlops/kubernetes/\n\nRefresh your API, and verify on the home page that it is now based on the new version of the model"
  },
  {
    "objectID": "slides/en/index.html#application-3-2",
    "href": "slides/en/index.html#application-3-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPart 3 : d√©ploiement continu d‚Äôun mod√®le de ML en tant qu‚ÄôAPI\n\n\n‚ö†Ô∏è The previous applications must have been created with the Git option to be able to follow this one.\nPreviously, you deployed your model manually. Thanks to ArgoCD, it is possible to deploy a model continuously. This means that every modification of a file in the kubernetes/ folder will automatically trigger redeployment, synchronized with your GitHub repository. To convince yourself, follow the steps below:\n\nDelete the manual deployment of the previous application to prevent Kubernetes resources from overlapping:\n\nkubectl delete -f formation-mlops/kubernetes/\n\nLaunch an ArgoCD service by clicking on this URL. Open the service, enter the username (admin), and the service‚Äôs password.\nCommit the changes made and push them to your GitHub repository.\nOpen the template argocd/template-argocd.yml and modify the highlighted lines:\n\n\n\ntemplate-argocd.yml\n\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/&lt;your-github-id&gt;/formation-mlops.git\n    targetRevision: HEAD\n    path: kubernetes\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: &lt;your-namespace&gt;\n\n\nIn ArgoCD, click on New App and then Edit as a YAML. Copy and paste the content of argocd/template-argocd.yml, and click on Create.\nReach your API using the URL defined in your ingress.yml file\nDisplay the documentation of your API by adding /docs to your URL\nTry your API out!\nRe-train a new model and deploy automatically this new model in your API\n\n\n\nClick to see the steps \n\n\nTrain a model\nRegister the model in MLflow\nAdjust your MLFLOW_MODEL_NAME or MLFLOW_MODEL_VERSION (if you didn‚Äôt modify the model name) environment variable in the deployment.yml file\nCommit these changes and push them to your GitHub repository.\nWait for 5 minutes for ArgoCD to automatically synchronize the changes from your GitHub repository, or force synchronization. Refresh your API and check on the homepage that it is now based on the new version of the model."
  },
  {
    "objectID": "slides/en/index.html#application-3-3",
    "href": "slides/en/index.html#application-3-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\nPart 4: Querying your deployed model\n\n\n\nCreate a file predict_api.py. This script should:\n\nRead the parquet file available at the following address:\n\nhttps://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet\n\nMake queries to your API for each label present in the parquet file.\nDisplay the prediction results.\n\n\n\n\nClick to see the script content \n\n\n\npredict_api.py\n\nimport pandas as pd\nimport requests\n\n\n# Function to make a request to the API\ndef make_prediction(api_url: str, description: str):\n    params = {\"description\": description, \"nb_echoes_max\": 2}\n    response = requests.get(api_url, params=params)\n    return response.json()\n\n\n# Data URL\ndata_path = \"https://minio.lab.sspcloud.fr/projet-formation/diffusion/mlops/data/data_to_classify.parquet\"\n\n# Load the Parquet file into a pandas DataFrame\ndf = pd.read_parquet(data_path)\n\n# API URL\napi_url = \"https://&lt;your_firstname&gt;-&lt;your_lastname&gt;-api.lab.sspcloud.fr/predict\"\n\n# Make the requests\nresponses = df[\"text\"].apply(lambda x: make_prediction(api_url, x))\n\n# Display the DataFrame with prediction results\nprint(pd.merge(df, pd.json_normalize(responses),\n               left_index=True,\n               right_index=True))\n\n\n\nRun your predict_api.py script.\n\n\n\nClick to see the command \n\npython formation-mlops/src/predict_api.py\n\n\nIn ArgoCD, open your application and click on your pod that should start with \"codification-api-...\". Observe the logs.\nWhat information do you have? Is it sufficient?\n\n\n\n\n\n\n\nImportant\n\n\nWe performed a series of GET requests here as we have a single entry point to our API. To perform batch queries, it is preferable to use POST requests."
  },
  {
    "objectID": "slides/en/index.html#summary-2",
    "href": "slides/en/index.html#summary-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/en/index.html#lifecycle-of-a-ml-model-in-production",
    "href": "slides/en/index.html#lifecycle-of-a-ml-model-in-production",
    "title": "An introduction to MLOps with MLflow",
    "section": "Lifecycle of a ML model in production",
    "text": "Lifecycle of a ML model in production"
  },
  {
    "objectID": "slides/en/index.html#the-challenge-of-responsibility",
    "href": "slides/en/index.html#the-challenge-of-responsibility",
    "title": "An introduction to MLOps with MLflow",
    "section": "The challenge of responsibility",
    "text": "The challenge of responsibility\n\nThe lifecycle of a ML model is complex\nSeveral stakeholders involved:\n\nData scientists\nIT/DevOps\nBusiness teams\n\nDifferent expertise and vocabulary between these stakeholders\n\n‚û°Ô∏è Communication essential between teams to monitor the model in production"
  },
  {
    "objectID": "slides/en/index.html#why-monitor-a-model-in-production",
    "href": "slides/en/index.html#why-monitor-a-model-in-production",
    "title": "An introduction to MLOps with MLflow",
    "section": "Why monitor a model in production?",
    "text": "Why monitor a model in production?\n\nDetect biased data: unalignment between production and training data\nAnticipate model instability: stable model performance over time\nContinuously improve the model: regular retraining\n\n‚ö†Ô∏è The term monitoring of an application/model has different definitions depending on the team."
  },
  {
    "objectID": "slides/en/index.html#monitoring-according-to-the-it-specialist",
    "href": "slides/en/index.html#monitoring-according-to-the-it-specialist",
    "title": "An introduction to MLOps with MLflow",
    "section": "Monitoring according to the IT specialist",
    "text": "Monitoring according to the IT specialist\n\nMonitoring an application is part of the DevOps approach\nTechnical control of the model:\n\nLatency\nMemory\nDisk usage\n‚Ä¶"
  },
  {
    "objectID": "slides/en/index.html#monitoring-according-to-the-data-scientist",
    "href": "slides/en/index.html#monitoring-according-to-the-data-scientist",
    "title": "An introduction to MLOps with MLflow",
    "section": "Monitoring according to the data scientist",
    "text": "Monitoring according to the data scientist\n\nMonitoring a ML model is part of the MLOps approach\nMethodological control of the model\nReal-time performance monitoring of the model often impossible, use of proxies:\n\nData drift: the input data distribution changes over time\nConcept drift: the modeled relationship changes over time"
  },
  {
    "objectID": "slides/en/index.html#how-to-monitor-a-model-in-production",
    "href": "slides/en/index.html#how-to-monitor-a-model-in-production",
    "title": "An introduction to MLOps with MLflow",
    "section": "How to monitor a model in production?",
    "text": "How to monitor a model in production?\n\nIntegration of logs in the API\nCollection and formatting of logs\nMonitoring of ML metrics\nImplementation of an alert system"
  },
  {
    "objectID": "slides/en/index.html#application-4",
    "href": "slides/en/index.html#application-4",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nPart 1: Logging business metrics\n\n\n\nUsing the logging package, add logs to your API. For each request, display the label to be coded as well as the responses returned by your API. To do this, modify the app/main.py file.\n\n\n\nClick to see the steps to complete \n\n\nImport the logging package:\n\n\n\nmain.py\n\nimport logging\n\n\nSet up your logging configuration before defining your first entry point:\n\n\n\nmain.py\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    handlers=[\n        logging.FileHandler(\"log_file.log\"),\n        logging.StreamHandler(),\n    ],\n)\n\n\nAdd the label and the API response to your logs:\n\n\n\nmain.py\n\n# Logging\nlogging.info(f\"{{'Query': {description}, 'Response': {predictions[0]}}}\")\n\n\n\nCommit your changes and push them to your remote repository.\nWhenever you make a change to your API, it needs to be redeployed for the changes to take effect. In theory, it would be necessary to rebuild a new image for our API containing the latest adjustments. To simplify, we have already built the two images with and without logs in the API. Until now you have used the image without logs, redeploy your API using the image with logs tagged as logs.\n\n\n\nClick to see the steps to complete \n\n\nIn the kubernetes/deployment.yml file, replace the no-logs tag with the logs tag:\n\n\n\ndeployment.yml\n\ntemplate:\n  metadata:\n    labels:\n      app: codification-api\n  spec:\n    containers:\n      - name: api\n        image: inseefrlab/formation-mlops:logs\n        imagePullPolicy: Always\n\n\nCommit your changes and push them to your remote repository.\nWait 5 minutes for ArgoCD to automatically synchronize the changes from your Github repository or force synchronization.\n\n\n\nRun your predict-api.py script.\n\n\n\nClick to see the command \n\npython formation-mlops/src/predict-api.py\n\n\nIn ArgoCD, open your application and click on your pod that should start with \"codification-api-...\". Observe the logs."
  },
  {
    "objectID": "slides/en/index.html#model-observability-through-a-dashboard",
    "href": "slides/en/index.html#model-observability-through-a-dashboard",
    "title": "An introduction to MLOps with MLflow",
    "section": "Model observability through a dashboard",
    "text": "Model observability through a dashboard\n\nAPI logs now contain business information\nFor processing/storage of logs: ETL pipeline\nTo analyze the behavior of the coding engine: creation of a dashboard\nMultiple solutions for the dashboard: Grafana, Quarto Dashboards, Apache Superset, ‚Ä¶"
  },
  {
    "objectID": "slides/en/index.html#an-example-stack",
    "href": "slides/en/index.html#an-example-stack",
    "title": "An introduction to MLOps with MLflow",
    "section": "An example stack",
    "text": "An example stack\n\nETL in the form of a cron job that parses logs and stores them in .parquet format\nUsing DuckDB to query the .parquet files\n‚Ä¶ and create the components of a Quarto Dashboard\nThe dashboard is a static site to be updated daily, for example"
  },
  {
    "objectID": "slides/en/index.html#an-example-stack-1",
    "href": "slides/en/index.html#an-example-stack-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "An example stack",
    "text": "An example stack"
  },
  {
    "objectID": "slides/en/index.html#application-4-1",
    "href": "slides/en/index.html#application-4-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nPart 2: Creating a monitoring dashboard\n\n\n\nWe will use Quarto Dashboards. Open the dashboard/index.qmd file and inspect the code. To retrieve the data needed to create the dashboard, we use a serverless DBMS: DuckDB. DuckDB allows us to run SQL queries on a .parquet file containing parsed logs. This file contains one row per prediction, with the variables timestamp, text, prediction_1, proba_1, prediction_2, and proba_2.\nTo visualize the dashboard, enter the following commands in a Terminal from the project root and click on the generated link.\ncd dashboard\nquarto preview index.qmd\nCurrently, the percentage of predictions with a probability greater than 0.8 does not correspond to reality. Modify the SQL query to obtain the pct_predictions variable to display the correct value.\n\n\n\nClick to see the answer \n\npct_predictions = duckdb.sql(\n    \"\"\"\n    SELECT 100 * COUNT(*) / COUNT(*)\n    FROM data;\n    \"\"\"\n).fetchall()[0][0]\n\n\nThe two charts at the bottom of the dashboard are also incorrect. Modify the SQL query to obtain the daily_stats variable to display the correct charts.\n\n\n\nClick to see the answer \n\ndaily_stats = duckdb.sql(\n    \"\"\"\n    SELECT\n        CAST(timestamp AS DATE) AS date,\n        COUNT(*) AS n_liasses,\n        (\n            COUNT(\n                CASE WHEN data.proba_1 &gt; 0.8 THEN 1 END\n            ) * 100.0 / COUNT(*)\n        ) AS pct_high_proba\n    FROM data\n    GROUP BY CAST(timestamp AS DATE);\n    \"\"\"\n).to_df()\n\nNotice the changes made to the dashboard."
  },
  {
    "objectID": "slides/en/index.html#summary-3",
    "href": "slides/en/index.html#summary-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "Summary",
    "text": "Summary"
  },
  {
    "objectID": "slides/en/index.html#parallel-training",
    "href": "slides/en/index.html#parallel-training",
    "title": "An introduction to MLOps with MLflow",
    "section": "Parallel training",
    "text": "Parallel training\n\nWith our setup, we can train models one by one and log all relevant information to the MLflow tracking server\nWhat if we would like to train multiple models at once, for example to optimize hyperparameters ?"
  },
  {
    "objectID": "slides/en/index.html#workflow-automation",
    "href": "slides/en/index.html#workflow-automation",
    "title": "An introduction to MLOps with MLflow",
    "section": "Workflow automation",
    "text": "Workflow automation\n\nGeneral principles :\n\nDefine workflows where each step in the workflow is a container (reproducibility)\nModel multi-step workflows as a sequence of tasks or as a directed acyclic graph\nThis allows to easily run in parallel compute intensive jobs for machine learning or data processing"
  },
  {
    "objectID": "slides/en/index.html#argo-workflows",
    "href": "slides/en/index.html#argo-workflows",
    "title": "An introduction to MLOps with MLflow",
    "section": "Argo workflows",
    "text": "Argo workflows\n\nA popular workflow engine for orchestrating parallel jobs on Kubernetes\n\nopen-source\ncontainer-native\navailable on the SSP Cloud"
  },
  {
    "objectID": "slides/en/index.html#hello-world",
    "href": "slides/en/index.html#hello-world",
    "title": "An introduction to MLOps with MLflow",
    "section": "Hello World",
    "text": "Hello World\napiVersion: argoproj.io/v1alpha1\nkind: Workflow                  # new type of k8s spec\nmetadata:\n  generateName: hello-world-    # name of the workflow spec\nspec:\n  entrypoint: whalesay          # invoke the whalesay template\n  templates:\n    - name: whalesay            # name of the template\n      container:\n        image: docker/whalesay\n        command: [ cowsay ]\n        args: [ \"hello world\" ]"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on",
    "href": "slides/en/index.html#what-is-going-on",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-1",
    "href": "slides/en/index.html#what-is-going-on-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-2",
    "href": "slides/en/index.html#what-is-going-on-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#parameters",
    "href": "slides/en/index.html#parameters",
    "title": "An introduction to MLOps with MLflow",
    "section": "Parameters",
    "text": "Parameters\n\nTemplates can take input parameters\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-parameters-\nspec:\n  entrypoint: whalesay\n  arguments:\n    parameters:\n    - name: message\n      value: hello world\n\n  templates:\n  - name: whalesay\n    inputs:\n      parameters:\n      - name: message       # parameter declaration\n    container:\n      image: docker/whalesay\n      command: [cowsay]\n      args: [\"{{inputs.parameters.message}}\"]"
  },
  {
    "objectID": "slides/en/index.html#multi-step-workflows",
    "href": "slides/en/index.html#multi-step-workflows",
    "title": "An introduction to MLOps with MLflow",
    "section": "Multi-step workflows",
    "text": "Multi-step workflows\n\nMulti-steps workflows can be specified (steps or dag)\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: steps-\nspec:\n  entrypoint: hello-hello-hello\n\n  # This spec contains two templates: hello-hello-hello and whalesay\n  templates:\n  - name: hello-hello-hello\n    # Instead of just running a container\n    # This template has a sequence of steps\n    steps:\n    - - name: hello1            # hello1 is run before the following steps\n        template: whalesay\n    - - name: hello2a           # double dash =&gt; run after previous step\n        template: whalesay\n      - name: hello2b           # single dash =&gt; run in parallel with previous step\n        template: whalesay\n  - name: whalesay              # name of the template\n    container:\n      image: docker/whalesay\n      command: [ cowsay ]\n      args: [ \"hello world\" ]"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-3",
    "href": "slides/en/index.html#what-is-going-on-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-4",
    "href": "slides/en/index.html#what-is-going-on-4",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-5",
    "href": "slides/en/index.html#what-is-going-on-5",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-6",
    "href": "slides/en/index.html#what-is-going-on-6",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#what-is-going-on-7",
    "href": "slides/en/index.html#what-is-going-on-7",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/en/index.html#further-applications",
    "href": "slides/en/index.html#further-applications",
    "title": "An introduction to MLOps with MLflow",
    "section": "Further applications",
    "text": "Further applications\n\nWorkflow to test registered models, or models pushed to staging / production\nWorkflows can be triggered automatically (via Argo Events for example)\nContinuous training workflows\nDistributed machine learning pipelines in general (data downloading, processing, etc.)"
  },
  {
    "objectID": "slides/en/index.html#further-applications-1",
    "href": "slides/en/index.html#further-applications-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Further applications",
    "text": "Further applications"
  },
  {
    "objectID": "slides/en/index.html#notes",
    "href": "slides/en/index.html#notes",
    "title": "An introduction to MLOps with MLflow",
    "section": "Notes",
    "text": "Notes\n\nPython SDK for Argo Workflows\nKubeflow pipelines\nCouler : unified interface for constructing and managing workflows on different workflow engines\nOther Python-native orchestration tools : Apache Airflow, Metaflow, Prefect"
  },
  {
    "objectID": "slides/en/index.html#application-5",
    "href": "slides/en/index.html#application-5",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 5",
    "text": "Application 5\n\n\n\nPart 1 : introduction to Argo Workflows\n\n\n\nLaunch an Argo Workflows service by clicking this URL. Open the service and input the service password (either automatically copied or available in the README of the service)\nIn VSCode, create a file hello_world.yaml at the root of the project with the following content:\n\n\n\nhello_world.yml\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-\n  labels:\n    workflows.argoproj.io/archive-strategy: \"false\"\n  annotations:\n    workflows.argoproj.io/description: |\n      This is a simple hello world example.\n      You can also run it in Python: https://couler-proj.github.io/couler/examples/#hello-world\nspec:\n  entrypoint: whalesay\n  templates:\n  - name: whalesay\n    container:\n      image: docker/whalesay:latest\n      command: [cowsay]\n      args: [\"hello world\"]\n\n\nSubmit the Hello world workflow via a terminal in VSCode :\n\nargo submit formation-mlops/hello_world.yaml\n\nOpen the UI of Argo Workflows. Find the logs of the workflow you just launched. You should see the Docker logo ."
  },
  {
    "objectID": "slides/en/index.html#application-4-2",
    "href": "slides/en/index.html#application-4-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nPart 2 : distributing the hyperparameters optimization\n\n\n\nTake a look at the argo_workflows/workflow.yml file. What do you expect will happen when we submit this workflow ?\nModify the highlighted line in the same manner as in application 3.\n\n\n\nworkflow.yml\n\nparameters:\n    # The MLflow tracking server is responsable to log the hyper-parameter and model metrics.\n    - name: mlflow-tracking-uri\n    value: https://user-&lt;namespace&gt;-&lt;pod_id&gt;.user.lab.sspcloud.fr\n    - name: mlflow-experiment-name\n    value: nace-prediction\n\n\nSubmit the workflow and look at the jobs completing live in the UI.\n\n\n\nClick to see the command \n\nargo submit formation-mlops/argo_workflows/workflow.yml\n\n\nOnce all jobs are completed, visualize the logs of the whole workflow.\nFinally, open the MLflow UI to check what has been done."
  },
  {
    "objectID": "slides/en/index.html#the-opportunity-for-more-continuous-organizations",
    "href": "slides/en/index.html#the-opportunity-for-more-continuous-organizations",
    "title": "An introduction to MLOps with MLflow",
    "section": "The opportunity for more continuous organizations",
    "text": "The opportunity for more continuous organizations"
  },
  {
    "objectID": "slides/en/index.html#required-transformations",
    "href": "slides/en/index.html#required-transformations",
    "title": "An introduction to MLOps with MLflow",
    "section": "Required transformations",
    "text": "Required transformations\n\nTransformations at different levels\n\nTechnical tools\nMethodological\nOrganizational\n\nStrategy: incremental change\n\nTraining\nApplication to pilot projects"
  }
]