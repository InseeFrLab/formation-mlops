[
  {
    "objectID": "slides/index.html#who-are-we",
    "href": "slides/index.html#who-are-we",
    "title": "An introduction to MLOps with MLflow",
    "section": "Who are we ?",
    "text": "Who are we ?\n\nData scientists at Insee\n\nmethodological and IT innovation teams\nsupport data science projects\n\nContact us\n\nromain.avouac at insee dot fr\nthomas.faria at insee dot fr\ntom.seimandi at insee dot fr"
  },
  {
    "objectID": "slides/index.html#context",
    "href": "slides/index.html#context",
    "title": "An introduction to MLOps with MLflow",
    "section": "Context",
    "text": "Context\n\nDifficulty of transitioning from experiments to production-grade machine learning systems\nLeverage best practices from software engineering\n\nImprove reproducibility of analysis\nDeploy applications in a scalable way"
  },
  {
    "objectID": "slides/index.html#the-devops-approach",
    "href": "slides/index.html#the-devops-approach",
    "title": "An introduction to MLOps with MLflow",
    "section": "The DevOps approach",
    "text": "The DevOps approach\n\nUnify development (dev) and system administration (ops)\n\nshorten development time\nmaintain software quality"
  },
  {
    "objectID": "slides/index.html#the-mlops-approach",
    "href": "slides/index.html#the-mlops-approach",
    "title": "An introduction to MLOps with MLflow",
    "section": "The MLOps approach",
    "text": "The MLOps approach\n\nIntegrate the specificities of machine learning projects\n\nExperimentation\nContinuous improvement"
  },
  {
    "objectID": "slides/index.html#mlops-principles",
    "href": "slides/index.html#mlops-principles",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLOps : principles",
    "text": "MLOps : principles\n\nReproducibility\nVersioning\nAutomation\nMonitoring\nCollaboration"
  },
  {
    "objectID": "slides/index.html#why-mlflow",
    "href": "slides/index.html#why-mlflow",
    "title": "An introduction to MLOps with MLflow",
    "section": "Why MLflow ?",
    "text": "Why MLflow ?\n\nMultiple frameworks implement the MLOps principles\nPros of MLflow\n\nOpen-source\nCovers the whole ML lifecycle\nAgnostic to the ML library used\nWe have experience with it"
  },
  {
    "objectID": "slides/index.html#training-platform-the-ssp-cloud",
    "href": "slides/index.html#training-platform-the-ssp-cloud",
    "title": "An introduction to MLOps with MLflow",
    "section": "Training platform : the SSP Cloud",
    "text": "Training platform : the SSP Cloud\n\nAn open innovation production-like environment\n\nKubernetes cluster\nS3-compatible object storage\nLarge computational resources (including GPUs)\n\nBased on the Onyxia project\n\nUser-friendly interface to launch data science services\nA catalog of services which covers the full lifecycle of data science projects"
  },
  {
    "objectID": "slides/index.html#outline",
    "href": "slides/index.html#outline",
    "title": "An introduction to MLOps with MLflow",
    "section": "Outline",
    "text": "Outline\n1️⃣ Introduction to MLFlow\n\n2️⃣ Deploying a model as an API\n\n\n3️⃣ Distributing the hyperparameter optimization"
  },
  {
    "objectID": "slides/index.html#application-0",
    "href": "slides/index.html#application-0",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 0",
    "text": "Application 0\n\n\n\nPreparation of the working environment\n\n\n\n\nCreate an account on the SSP Cloud using your professional mail address\nLaunch a MLflow service by clicking this URL\nLaunch a VSCode service by clicking this URL\nOpen the VSCode service and input the service password (either automatically copied or available in the README of the service)\nYou’re all set !"
  },
  {
    "objectID": "slides/index.html#tracking-server",
    "href": "slides/index.html#tracking-server",
    "title": "An introduction to MLOps with MLflow",
    "section": "Tracking server",
    "text": "Tracking server\n\n“An API and UI for logging parameters, code versions, metrics, and artifacts”"
  },
  {
    "objectID": "slides/index.html#projects",
    "href": "slides/index.html#projects",
    "title": "An introduction to MLOps with MLflow",
    "section": "Projects",
    "text": "Projects\n\n“A standard format for packaging reusable data science code”"
  },
  {
    "objectID": "slides/index.html#models",
    "href": "slides/index.html#models",
    "title": "An introduction to MLOps with MLflow",
    "section": "Models",
    "text": "Models\n\n“A convention for packaging machine learning models in multiple flavors”"
  },
  {
    "objectID": "slides/index.html#model-registry",
    "href": "slides/index.html#model-registry",
    "title": "An introduction to MLOps with MLflow",
    "section": "Model registry",
    "text": "Model registry\n\n“A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an MLflow Model”"
  },
  {
    "objectID": "slides/index.html#application-1",
    "href": "slides/index.html#application-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 1",
    "text": "Application 1\n\n\n\nIntroduction to MLflow concepts\n\n\n\n\nIn VSCode, open the notebook mlflow-introduction.ipynb (from the notebooks directory)\nChoose our custom Python kernel :\n\nSelect Kernel -&gt; Python environments... -&gt; base (Python 3.x.x)\n\nExecute the notebook cell by cell. Try to understand carefully how the Python session interacts with the MLflow API. Explore the MLflow UI and try to build your own experiments from the example code provided in the notebook."
  },
  {
    "objectID": "slides/index.html#context-1",
    "href": "slides/index.html#context-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Context",
    "text": "Context\n\nNACE\n\nEuropean standard classification of productive economic activities\nHierarchical structure with 4 levels and 615 codes\n\nAt Insee previously handled by an outdated rule-based algorithm\nCommon problematic to all National statistical institutes"
  },
  {
    "objectID": "slides/index.html#data-used",
    "href": "slides/index.html#data-used",
    "title": "An introduction to MLOps with MLflow",
    "section": "Data used",
    "text": "Data used\n\nSlideRawPreprocessed\n\n\n\nA simple use-case with only 2 variables:\n\nTextual description of the activity – text\nTrue NACE code labelised by the rule-based engine – nace (732 modalities)\n\nStandard preprocessing:\n\nlowercasing\npunctuation removal\nnumber removal\nstopwords removal\nstemming\n…\n\n\n\n\n\nviewof table_data = Inputs.table(transpose(data_raw), {\n    rows: 22\n})\n\n\n\n\n\n\n\n\n\nviewof table_data_prepro = Inputs.table(transpose(data_prepro), {\n    rows: 22\n})"
  },
  {
    "objectID": "slides/index.html#mlflow-with-a-non-standard-framework",
    "href": "slides/index.html#mlflow-with-a-non-standard-framework",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLflow with a non standard framework",
    "text": "MLflow with a non standard framework\n\n\n\nEasy to use with a variety of machine learning frameworks (scikit-learn, Keras, Pytorch…)\n\n\n\nmlflow.sklearn.log_model(pipe_rf, \"model\")\n\nmlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{version}\")\ny_train_pred = model.predict(X_train)\n\n\n\nWhat if we require greater flexibility or our own framework?\n\n\n\n\nPossibility to track , register and deliver your own model"
  },
  {
    "objectID": "slides/index.html#mlflow-with-a-non-standard-framework-1",
    "href": "slides/index.html#mlflow-with-a-non-standard-framework-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "MLflow with a non standard framework",
    "text": "MLflow with a non standard framework\n\n\n\nThere are 2 main differences when using your own framework:\n\nlogging of parameters, metrics and artifacts\nwrapping of your custom model so that MLflow can serve it\n\n\n\n\n# Define a custom model\nclass MyModel(mlflow.pyfunc.PythonModel):\n\n    def load_context(self, context):\n      self.my_model.load_model(context.artifacts[\"my_model\"])\n\n    def predict(self, context, model_input):\n        return self.my_model.predict(model_input)"
  },
  {
    "objectID": "slides/index.html#necessity-of-avoiding-notebooks-for-production-deployment",
    "href": "slides/index.html#necessity-of-avoiding-notebooks-for-production-deployment",
    "title": "An introduction to MLOps with MLflow",
    "section": "Necessity of avoiding notebooks for production deployment",
    "text": "Necessity of avoiding notebooks for production deployment\n\nArguments against using notebooks for ML models deployment:\n\nLimited scalability for automation of ML pipelines.\nLack of clear and reproducible workflows.\nHinders collaboration and versioning among team members.\nInsufficient modularity for managing complex ML components."
  },
  {
    "objectID": "slides/index.html#application-2",
    "href": "slides/index.html#application-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\n\nPart 1 : From notebook to python scripts\n\n\n\nAll scripts related to our custom model are stored in the src folder. Check them out. Have a look at the MLproject file as well.\nRun a training of the model using MLflow. To do so:\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n-P remote_server_uri=$MLFLOW_TRACKING_URI \\\n-P experiment_name=\"fasttext\"\nLook at the results of your previous run:\n\nExperiments -&gt; fasttext -&gt; &lt;run_name&gt;\n\nYou have trained the model with some default parameters. In MLproject check the parameters available. Re-train a model with different parameters (i.e. dim = 25).\n\n\n\nClick to see the command \n\nmlflow run ~/work/formation-mlops/ --env-manager=local \\\n-P remote_server_uri=$MLFLOW_TRACKING_URI \\\n-P experiment_name=\"fasttext\"\n-P dim=25\n\n\nIn MLflow, compare the 2 models by plotting the accuracy against one parameter you have changed (i.e. dim)\n\nSelect the 2 runs -&gt; Compare -&gt; Scatter Plot -&gt; Select your X and Y axis"
  },
  {
    "objectID": "slides/index.html#application-2-1",
    "href": "slides/index.html#application-2-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 2",
    "text": "Application 2\n\n\n\n\nPart 2 : Model delivery with onboarded preprocessing\n\n\n\nExplore the src/train.py file carefully. What are the main differences compare to application 1 ?\nWhy can we say that the MLflow model onboard the preprocessing ?\nIn MLflow, register your last model\nOpen and run the notebook mlflow-custom-model.ipynb which loads your model from the model store.\nRead the documentation of the predict() function of the custom class (src/fasttext_wrapper.py)\nMake a prediction of the model\n\n\n\nClick to see the command \n\nlist_libs = [\"vendeur d'huitres\", \"boulanger\"]\n\ntest_data = {\n    \"query\": list_libs,\n    \"k\": 1\n}\nmodel.predict(test_data)\n\n\nMake sure that the two following descriptions give the same results: \"COIFFEUR\" and \"coiffeur, & 98789\"\nChange the value of the parameter k"
  },
  {
    "objectID": "slides/index.html#exposing-a-model-via-an-api",
    "href": "slides/index.html#exposing-a-model-via-an-api",
    "title": "An introduction to MLOps with MLflow",
    "section": "Exposing a model via an API",
    "text": "Exposing a model via an API\n\nAPI: interface between the user (client) and the trained model\nAPI REST: allows querying the model using a simple syntax (HTTP) in a scalable manner\nFor more details on constructing an API, refer to the documentation of FastAPI"
  },
  {
    "objectID": "slides/index.html#run-the-api-in-a-container",
    "href": "slides/index.html#run-the-api-in-a-container",
    "title": "An introduction to MLOps with MLflow",
    "section": "Run the API in a container",
    "text": "Run the API in a container\n\nContainer: self-contained and isolated environment that encapsulates your model, its dependencies and API code\nContainers provide high portability and scalability for distributing your model efficiently.\nThe Dockerfile is used to configure and build the Docker container."
  },
  {
    "objectID": "slides/index.html#deploying-an-api",
    "href": "slides/index.html#deploying-an-api",
    "title": "An introduction to MLOps with MLflow",
    "section": "Deploying an API",
    "text": "Deploying an API\n\n\n3 main files are needed to deploy an API:\n\ndeployment.yaml : defines how the API should run (container image, resources, and env variables)\nservice.yaml : establishes a stable internal network endpoint for the API.\ningress.yaml : provides an entry point for external clients to access the API.\n\nArgo CD:\n\nDeployment tool used to automate and simplify the deployment process."
  },
  {
    "objectID": "slides/index.html#application-3",
    "href": "slides/index.html#application-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 3",
    "text": "Application 3\n\n\n\n\nDeploying a machine-learning model as an API\n\n\n\nWe constructed a very simplistic Rest API using FastAPI. All underlying files are in the app folder. Check it.\nOpen the Dockerfile to see how the image is built. The image is publish via Github Actions, if interested have a look to .github/workflows/build_image.yml.\nOpen the file kubernetes/deployment.yml and modify the highlighted lines accordingly:\n\ncontainers:\n- name: api\n    image: inseefrlab/formation-mlops-api:main\n    imagePullPolicy: Always\n    env:\n    - name: MLFLOW_TRACKING_URI\n        value: https://projet-formation-******.user.lab.sspcloud.fr\n    - name: MLFLOW_MODEL_NAME\n        value: fasttext-model\n    - name: MLFLOW_MODEL_VERSION\n        value: \"1\"\n\nOn the SSP Cloud, launch an Argo-cd service by clicking this URL\nCreate a new application and use the yaml template stored in the argocd folder\n\nCreate an application  -&gt; Edit as YAML\nAdjust the yaml to your purpose\nSave -&gt; Create\n\nReach your API using the URL you defined in your ingress.yml file\nDisplay the documentation of your API by adding /docs to your URL\nTry your API out!\nRe-run a new model and deploy this new model in your API\n\n\n\nClick to see the steps \n\n\nRun a model\nRegister the model\nAdjust your MLFLOW_MODEL_NAME or MLFLOW_MODEL_VERSION environment variable in the deployment.yml file\nCommit and push these changes\nSynchronise in Argo-cd or wait for 5 minutes\nRefresh your API, it should be based on your new version!"
  },
  {
    "objectID": "slides/index.html#parallel-training",
    "href": "slides/index.html#parallel-training",
    "title": "An introduction to MLOps with MLflow",
    "section": "Parallel training",
    "text": "Parallel training\n\nWith our setup, we can train models one by one and log all relevant information to the MLflow tracking server\nWhat if we would like to train multiple models at once, for example to optimize hyperparameters ?"
  },
  {
    "objectID": "slides/index.html#workflow-automation",
    "href": "slides/index.html#workflow-automation",
    "title": "An introduction to MLOps with MLflow",
    "section": "Workflow automation",
    "text": "Workflow automation\n\nArgo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes\nAvailable on the SSP Cloud\nGeneral principles :\n\nDefine workflows where each step in the workflow is a container\nModel multi-step workflows as a sequence of tasks or as a directed acyclic graph\nThis allows to easily run in parallel compute intensive jobs for machine learning or data processing"
  },
  {
    "objectID": "slides/index.html#hello-world",
    "href": "slides/index.html#hello-world",
    "title": "An introduction to MLOps with MLflow",
    "section": "Hello World",
    "text": "Hello World\napiVersion: argoproj.io/v1alpha1\nkind: Workflow                  # new type of k8s spec\nmetadata:\n  generateName: hello-world-    # name of the workflow spec\nspec:\n  entrypoint: whalesay          # invoke the whalesay template\n  templates:\n    - name: whalesay            # name of the template\n      container:\n        image: docker/whalesay\n        command: [ cowsay ]\n        args: [ \"hello world\" ]"
  },
  {
    "objectID": "slides/index.html#what-is-going-on",
    "href": "slides/index.html#what-is-going-on",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-1",
    "href": "slides/index.html#what-is-going-on-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-2",
    "href": "slides/index.html#what-is-going-on-2",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#parameters",
    "href": "slides/index.html#parameters",
    "title": "An introduction to MLOps with MLflow",
    "section": "Parameters",
    "text": "Parameters\n\nTemplates can take input parameters\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: hello-world-parameters-\nspec:\n  entrypoint: whalesay\n  arguments:\n    parameters:\n    - name: message\n      value: hello world\n\n  templates:\n  - name: whalesay\n    inputs:\n      parameters:\n      - name: message       # parameter declaration\n    container:\n      image: docker/whalesay\n      command: [cowsay]\n      args: [\"{{inputs.parameters.message}}\"]"
  },
  {
    "objectID": "slides/index.html#multi-step-workflows",
    "href": "slides/index.html#multi-step-workflows",
    "title": "An introduction to MLOps with MLflow",
    "section": "Multi-step workflows",
    "text": "Multi-step workflows\n\nMulti-steps workflows can be specified (steps or dag)\n\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n  generateName: steps-\nspec:\n  entrypoint: hello-hello-hello\n\n  # This spec contains two templates: hello-hello-hello and whalesay\n  templates:\n  - name: hello-hello-hello\n    # Instead of just running a container\n    # This template has a sequence of steps\n    steps:\n    - - name: hello1            # hello1 is run before the following steps\n        template: whalesay\n    - - name: hello2a           # double dash =&gt; run after previous step\n        template: whalesay\n      - name: hello2b           # single dash =&gt; run in parallel with previous step\n        template: whalesay\n  - name: whalesay              # name of the template\n    container:\n      image: docker/whalesay\n      command: [ cowsay ]\n      args: [ \"hello world\" ]"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-3",
    "href": "slides/index.html#what-is-going-on-3",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-4",
    "href": "slides/index.html#what-is-going-on-4",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-5",
    "href": "slides/index.html#what-is-going-on-5",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-6",
    "href": "slides/index.html#what-is-going-on-6",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#what-is-going-on-7",
    "href": "slides/index.html#what-is-going-on-7",
    "title": "An introduction to MLOps with MLflow",
    "section": "What is going on ?",
    "text": "What is going on ?"
  },
  {
    "objectID": "slides/index.html#further-applications",
    "href": "slides/index.html#further-applications",
    "title": "An introduction to MLOps with MLflow",
    "section": "Further applications",
    "text": "Further applications\n\nWorkflow to test registered models, or models pushed to staging / production\nWorkflows can be triggered automatically (via Argo Events for example)\nContinuous training workflows\nDistributed machine learning pipelines in general (data downloading, processing, etc.)"
  },
  {
    "objectID": "slides/index.html#further-applications-1",
    "href": "slides/index.html#further-applications-1",
    "title": "An introduction to MLOps with MLflow",
    "section": "Further applications",
    "text": "Further applications"
  },
  {
    "objectID": "slides/index.html#notes",
    "href": "slides/index.html#notes",
    "title": "An introduction to MLOps with MLflow",
    "section": "Notes",
    "text": "Notes\n\nPython SDK for Argo Workflows\nKubeflow pipelines\nCouler : unified interface for constructing and managing workflows on different workflow engines\nOther Python-native orchestration tools : Apache Airflow, Metaflow, Prefect"
  },
  {
    "objectID": "slides/index.html#application-4",
    "href": "slides/index.html#application-4",
    "title": "An introduction to MLOps with MLflow",
    "section": "Application 4",
    "text": "Application 4\n\n\n\nDistributing the hyperparameter optimization with an orchestrator\n\n\n\n\nOpen an Argo Workflows service and submit the Hello World workflow. Visualize the logs on the Argo Workflows UI.\nTake a look at the argo_workflows/workflow.yml file. What do you expect will happen when we submit this workflow ?\nSubmit the workflow. Once all jobs are completed, visualize the logs. Then open the MLflow UI to check what has been done."
  }
]