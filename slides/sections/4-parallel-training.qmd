## Parallel training

- With our setup, we can train models [**one by one**]{.orange} and log all relevant information to the MLflow tracking server
- What if we would like to train [**multiple models at once**]{.orange}, for example to optimize hyperparameters ?

## Workflow automation

- General principles :
    - Define workflows where each step in the workflow is a [**container**]{.blue2} (reproducibility)
    - Model multi-step workflows as a [**sequence**]{.blue2} of tasks or as a [**directed acyclic graph**]{.blue2}
    - This allows to easily [**run in parallel compute intensive jobs**]{.blue2} for machine learning or data processing

## Argo workflows

- A popular [**workflow engine**]{.orange} for orchestrating parallel jobs on `Kubernetes`
  - [**open-source**]{.blue2}
  - [**container-native**]{.blue2}
  - available on the [**SSP Cloud**]{.orange}

![](img/argo-logo.png){fig-align="center" height=300}

## Hello World

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow                  # new type of k8s spec
metadata:
  generateName: hello-world-    # name of the workflow spec
spec:
  entrypoint: whalesay          # invoke the whalesay template
  templates:
    - name: whalesay            # name of the template
      container:
        image: docker/whalesay
        command: [ cowsay ]
        args: [ "hello world" ]
```

## What is going on ?

. . .

![](img/argo-0.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-1a.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-2a.png){fig-align="center" height=500}

## Parameters

- Templates can take [**input parameters**]{.orange}

. . .

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: hello-world-parameters-
spec:
  entrypoint: whalesay
  arguments:
    parameters:
    - name: message
      value: hello world

  templates:
  - name: whalesay
    inputs:
      parameters:
      - name: message       # parameter declaration
    container:
      image: docker/whalesay
      command: [cowsay]
      args: ["{{inputs.parameters.message}}"]
```

## Multi-step workflows

- [**Multi-steps workflows**]{.orange} can be specified (`steps` or `dag`)

. . .

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: steps-
spec:
  entrypoint: hello-hello-hello

  # This spec contains two templates: hello-hello-hello and whalesay
  templates:
  - name: hello-hello-hello
    # Instead of just running a container
    # This template has a sequence of steps
    steps:
    - - name: hello1            # hello1 is run before the following steps
        template: whalesay
    - - name: hello2a           # double dash => run after previous step
        template: whalesay
      - name: hello2b           # single dash => run in parallel with previous step
        template: whalesay
  - name: whalesay              # name of the template
    container:
      image: docker/whalesay
      command: [ cowsay ]
      args: [ "hello world" ]
```

## What is going on ?

. . .

![](img/argo-0.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-1b.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-2b.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-1b.png){fig-align="center" height=500}

## What is going on ?

![](img/argo-3b.png){fig-align="center" height=500}

## Further applications

- Workflow [**to test**]{.orange} registered models, or models pushed to staging / production
- Workflows can be [**triggered**]{.orange} automatically (via Argo Events for example)
- [**Continuous training workflows**]{.orange}
- [**Distributed**]{.orange} machine learning pipelines in general (data downloading, processing, etc.)

## Further applications

. . .

![](img/pokemon_workflow.png){fig-align="center" height=450}

## Notes

- [**Python SDK**]{.orange} for Argo Workflows
- Kubeflow pipelines
- [**Couler**]{.orange} : unified interface for constructing and managing workflows on different workflow engines
- Other Python-native orchestration tools : [**Apache Airflow**]{.orange}, [**Metaflow**]{.orange}, [**Prefect**]{.orange}

